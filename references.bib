@inproceedings{adamic_etal_2005,
author = {Adamic, Lada A. and Glance, Natalie},
title = {The Political Blogosphere and the 2004 U.S. Election: Divided They Blog},
year = {2005},
isbn = {1595932151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134271.1134277},
doi = {10.1145/1134271.1134277},
abstract = {In this paper, we study the linking patterns and discussion topics of political bloggers. Our aim is to measure the degree of interaction between liberal and conservative blogs, and to uncover any differences in the structure of the two communities. Specifically, we analyze the posts of 40 "A-list" blogs over the period of two months preceding the U.S. Presidential Election of 2004, to study how often they referred to one another and to quantify the overlap in the topics they discussed, both within the liberal and conservative communities, and also across communities. We also study a single day snapshot of over 1,000 political blogs. This snapshot captures blogrolls (the list of links to other blogs frequently found in sidebars), and presents a more static picture of a broader blogosphere. Most significantly, we find differences in the behavior of liberal and conservative blogs, with conservative blogs linking to each other more frequently and in a denser pattern.},
booktitle = {Proceedings of the 3rd International Workshop on Link Discovery},
pages = {36–43},
numpages = {8},
keywords = {social networks, political blogs, link analysis},
location = {Chicago, Illinois},
series = {LinkKDD '05}
}

@article{buechel_etal_2018,
  author       = {Sven Buechel and
                  Anneke Buffone and
                  Barry Slaff and
                  Lyle H. Ungar and
                  Jo{\~{a}}o Sedoc},
  title        = {Modeling Empathy and Distress in Reaction to News Stories},
  journal      = {CoRR},
  volume       = {abs/1808.10399},
  year         = {2018},
  url          = {http://arxiv.org/abs/1808.10399},
  eprinttype    = {arXiv},
  eprint       = {1808.10399},
  timestamp    = {Mon, 03 Sep 2018 13:36:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1808-10399.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{burger_etal_2011,
author = {Burger, John D. and Henderson, John and Kim, George and Zarrella, Guido},
title = {Discriminating Gender on Twitter},
year = {2011},
isbn = {9781937284114},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.},
booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {1301–1309},
numpages = {9},
location = {Edinburgh, United Kingdom},
series = {EMNLP '11}
}

@article{chung_pennebaker_2008,
title = {Revealing dimensions of thinking in open-ended self-descriptions: An automated meaning extraction method for natural language},
journal = {Journal of Research in Personality},
volume = {42},
number = {1},
pages = {96-132},
year = {2008},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2007.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0092656607000451},
author = {Cindy K. Chung and James W. Pennebaker},
keywords = {LIWC, Meaning extraction method, Natural language, Self-descriptions},
abstract = {A new method for extracting common themes from written text is introduced and applied to 1165 open-ended self-descriptive narratives. Drawing on a lexical approach to personality, the most commonly-used adjectives within narratives written by college students were identified using computerized text analytic tools. A factor analysis on the use of these adjectives in the self-descriptions produced a 7-factor solution consisting of psychologically meaningful dimensions. Some dimensions were unipolar (e.g., Negativity factor, wherein most loaded items were negatively valenced adjectives); others were dimensional in that semantically opposite words clustered together (e.g., Sociability factor, wherein terms such as shy, outgoing, reserved, and loud all loaded in the same direction). The factors exhibited modest reliability across different types of writing samples and were correlated with self-reports and behaviors consistent with the dimensions. Similar analyses with additional content words (adjectives, adverbs, nouns, and verbs) yielded additional psychological dimensions associated with physical appearance, school, relationships, etc. in which people contextualize their self-concepts. The results suggest that the meaning extraction method is a promising strategy that determines the dimensions along which people think about themselves.}
}

@inproceedings{dingemanse_liesenfeld_2022,
    title = "From text to talk: {H}arnessing conversational corpora for humane and diversity-aware language technology",
    author = "Dingemanse, Mark  and
      Liesenfeld, andreas",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.385",
    doi = "10.18653/v1/2022.acl-long.385",
    pages = "5614--5633",
    abstract = "Informal social interaction is the primordial home of human language. Linguistically diverse conversational corpora are an important and largely untapped resource for computational linguistics and language technology. Through the efforts of a worldwide language documentation movement, such corpora are increasingly becoming available. We show how interactional data from 63 languages (26 families) harbours insights about turn-taking, timing, sequential structure and social action, with implications for language technology, natural language understanding, and the design of conversational interfaces. Harnessing linguistically diverse conversational corpora will provide the empirical foundations for flexible, localizable, humane language technologies of the future.",
}

@article{davies_2009,
  title={The 385+ million word Corpus of Contemporary American English (1990―2008+): Design, architecture, and linguistic insights},
  author={Mark Davies},
  journal={International Journal of Corpus Linguistics},
  year={2009},
  volume={14},
  pages={159-190},
  url={https://www.english-corpora.org//coca/}
}

@article{downs_etal_2017,
  title={Detection of Suicidality in Adolescents with Autism Spectrum Disorders: Developing a Natural Language Processing Approach for Use in Electronic Health Records},
  author={Johnny M Downs and Sumithra Velupillai and George Gkotsis and Rachel Holden and Maxim Kikoler and Harry Dean and andrea C. Fernandes and Rina Dutta},
  journal={AMIA ... Annual Symposium proceedings. AMIA Symposium},
  year={2017},
  volume={2017},
  pages={
          641-649
        },
  url={https://api.semanticscholar.org/CorpusID:7388358}
}

@article{eichstaedt_etal_2015,
author = {Johannes C. Eichstaedt and Hansen andrew Schwartz and Margaret L. Kern and Gregory Park and Darwin R. Labarthe and Raina M. Merchant and Sneha Jha and Megha Agrawal and Lukasz A. Dziurzynski and Maarten Sap and Christopher Weeg and Emily E. Larson and Lyle H. Ungar and Martin E. P. Seligman},
title ={Psychological Language on Twitter Predicts County-Level Heart Disease Mortality},
journal = {Psychological Science},
volume = {26},
number = {2},
pages = {159-169},
year = {2015},
doi = {10.1177/0956797614557867},
note ={PMID: 25605707},
URL = {https://osf.io/rt6w2/},
eprint = {https://doi.org/10.1177/0956797614557867},
abstract = { Hostility and chronic stress are known risk factors for heart disease, but they are costly to assess on a large scale. We used language expressed on Twitter to characterize community-level psychological correlates of age-adjusted mortality from atherosclerotic heart disease (AHD). Language patterns reflecting negative social relationships, disengagement, and negative emotions—especially anger—emerged as risk factors; positive emotions and psychological engagement emerged as protective factors. Most correlations remained significant after controlling for income and education. A cross-sectional regression model based only on Twitter language predicted AHD mortality significantly better than did a model that combined 10 common demographic, socioeconomic, and health risk factors, including smoking, diabetes, hypertension, and obesity. Capturing community psychological characteristics through social media is feasible, and these characteristics are strong markers of cardiovascular mortality at the community level. }
}

@article{golder_macy_2011,
author = {Scott A. Golder  and Michael W. Macy },
title = {Diurnal and Seasonal Mood Vary with Work, Sleep, and Daylength Across Diverse Cultures},
journal = {Science},
volume = {333},
number = {6051},
pages = {1878-1881},
year = {2011},
doi = {10.1126/science.1202775},
URL = {https://www.science.org/doi/abs/10.1126/science.1202775},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1202775},
abstract = {Across the world the collective mood heightens
at breakfast time and during the weekend. We identified individual-level diurnal and seasonal mood rhythms in cultures across the globe, using data from millions of public Twitter messages. We found that individuals awaken in a good mood that deteriorates as the day progresses—which is consistent with the effects of sleep and circadian rhythm—and that seasonal change in baseline positive affect varies with change in daylength. People are happier on weekends, but the morning peak in positive affect is delayed by 2 hours, which suggests that people awaken later on weekends.}
}

@article{hellman_2011,
abstract = {This study investigated whether adult‐onset second language (L2) learners achieve native level vocabulary after decades of immersion. Vocabulary tests were given to three groups of participants: highly successful adult‐onset learners of English, monolingual English speakers, and bilingual native speakers of English. Overall, the native speakers outperformed the non‐native speakers; however, the rate of native like achievement was remarkably high among the successful adult‐onset learners, which indicated that native level L2 vocabulary size and depth of word knowledge were attainable in adulthood. Factors that correlated with native level L2 vocabulary were: childhood caregivers' education, verbal ability and literacy in the native language, and interest in word learning and daily reading. The findings suggest that the lexicon may be the potentially most successful area of adult‐onset L2 learning.},
author = {Hellman, Andrea B.},
address = {Oxford, UK},
copyright = {2010 Blackwell Publishing Ltd},
issn = {0802-6106},
journal = {International journal of applied linguistics},
keywords = {adult language learning ; angol nyelv ; bilingualism ; Foreign language learning ; idegennyelv tanulás ; Language acquisition ; lexical development ; native vs. non-native speakers ; nyelvoktatás ; second language acquisition ; szókincs ; szókincsfelmérés ; vocabulary ; Vocabulary development},
language = {eng},
number = {2},
pages = {162-182},
publisher = {Blackwell Publishing Ltd},
title = {Vocabulary size and depth of word knowledge in adult-onset second language acquisition},
volume = {21},
year = {2011},
}

@article{holtgraves_2011,
title = {Text messaging, personality, and the social context},
journal = {Journal of Research in Personality},
volume = {45},
number = {1},
pages = {92-99},
year = {2011},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2010.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0092656610001698},
author = {Thomas Holtgraves},
keywords = {Texting, Language, Personality, Language use},
abstract = {The purpose of this research was to undertake some analyses of how the language used in text messaging varies as a function of personality traits and the interpersonal context. After completing personality questionnaires, participants provided their most recent text messages and indicated their relationship with the message recipient on several dimensions. Correlations between Linguistic Inquiry and Word Count (LIWC) categories and personality traits and relationship status were examined. There were significant correlations between certain LIWC categories and extraversion (e.g., personal pronouns), neuroticism (e.g., negative emotion words) and agreeableness (e.g., positive emotion words), suggesting that personality traits are displayed in how one texts. One of the defining features of texting – linguistic alterations (e.g., abbreviations) – varied as a function of both personality traits and relationship status. Overall, the results provide a snapshot of what text messages look like, and how they reflect the texter’s personality and the interpersonal context.}
}

@inbook{kennedy_etal_2022,
author = "Brendan Kennedy and Ashwini Ashokkumar and Boyd, {Ryan L} and Morteza Dehghani",
title = "Text Analysis for Psychology: Methods, Principles, and Practices",
year = "2022",
month = jan,
day = "7",
pages = "3-64",
language = "English",
isbn = "9781462548439",
editor = "Morteza Dehghani and Boyd, {Ryan L}",
booktitle = "Handbook of Language Analysis in Psychology",
publisher = "Guilford Press",
}

@article{kessler_2017,
  author    = {Kessler, Jason S.},
  title     = {Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ},
  booktitle = {Proceedings of ACL-2017 System Demonstrations},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
}

@article{kosinski_etal_2013,
author = {Michal Kosinski  and David Stillwell  and Thore Graepel },
title = {Private traits and attributes are predictable from digital records of human behavior},
journal = {Proceedings of the National Academy of Sciences},
volume = {110},
number = {15},
pages = {5802-5805},
year = {2013},
doi = {10.1073/pnas.1218772110},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1218772110},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1218772110},
abstract = {We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88\% of cases, African Americans and Caucasian Americans in 95\% of cases, and between Democrat and Republican in 85\% of cases. For the personality trait “Openness,” prediction accuracy is close to the test–retest accuracy of a standard personality test. We give examples of associations between attributes and Likes and discuss implications for online personalization and privacy.}
}

@article{kozlowski_etal_2019,
author = {Austin C. Kozlowski and Matt Taddy and James A. Evans},
title ={The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings},
journal = {American Sociological Review},
volume = {84},
number = {5},
pages = {905-949},
year = {2019},
doi = {10.1177/0003122419877135},
URL = {https://doi.org/10.1177/0003122419877135},
eprint = {https://doi.org/10.1177/0003122419877135},
abstract = { We argue word embedding models are a useful tool for the study of culture using a historical analysis of shared understandings of social class as an empirical case. Word embeddings represent semantic relations between words as relationships between vectors in a high-dimensional space, specifying a relational model of meaning consistent with contemporary theories of culture. Dimensions induced by word differences (rich – poor) in these spaces correspond to dimensions of cultural meaning, and the projection of words onto these dimensions reflects widely shared associations, which we validate with surveys. Analyzing text from millions of books published over 100 years, we show that the markers of class continuously shifted amidst the economic transformations of the twentieth century, yet the basic cultural dimensions of class remained remarkably stable. The notable exception is education, which became tightly linked to affluence independent of its association with cultivated taste. }
}

@article{kulkarni_etal_2018,
doi = {10.1371/journal.pone.0201703},
author = {Kulkarni, Vivek and Kern, Margaret L. and Stillwell, David and Kosinski, Michal and Matz, Sandra and Ungar, Lyle and Skiena, Steven and Schwartz, H. andrew},
journal = {PLOS ONE},
publisher = {Public Library of Science},
title = {Latent human traits in the language of social media: An open-vocabulary approach},
year = {2018},
month = {11},
volume = {13},
url = {https://doi.org/10.1371/journal.pone.0201703},
pages = {1-18},
abstract = {Over the past century, personality theory and research has successfully identified core sets of characteristics that consistently describe and explain fundamental differences in the way people think, feel and behave. Such characteristics were derived through theory, dictionary analyses, and survey research using explicit self-reports. The availability of social media data spanning millions of users now makes it possible to automatically derive characteristics from behavioral data—language use—at large scale. Taking advantage of linguistic information available through Facebook, we study the process of inferring a new set of potential human traits based on unprompted language use. We subject these new traits to a comprehensive set of evaluations and compare them with a popular five factor model of personality. We find that our language-based trait construct is often more generalizable in that it often predicts non-questionnaire-based outcomes better than questionnaire-based traits (e.g. entities someone likes, income and intelligence quotient), while the factors remain nearly as stable as traditional factors. Our approach suggests a value in new constructs of personality derived from everyday human language use.},
number = {11},
}

@article{lazer_etal_2009,
author = {David Lazer  and Alex Pentland  and Lada Adamic  and Sinan Aral  and Albert-László Barabási  and Devon Brewer  and Nicholas Christakis  and Noshir Contractor  and James Fowler  and Myron Gutmann  and Tony Jebara  and Gary King  and Michael Macy  and Deb Roy  and Marshall Van Alstyne },
title = {Computational Social Science},
journal = {Science},
volume = {323},
number = {5915},
pages = {721-723},
year = {2009},
doi = {10.1126/science.1167742},
URL = {https://www.science.org/doi/abs/10.1126/science.1167742},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1167742}
}

@inproceedings{le_etal_2011,
  title={Diurnal and Seasonal Mood Vary with Work, Sleep, and Daylength Across Diverse Cultures},
  author={Hiep D. Le and Christopher Vollmers and Megumi Hatori and Michael Witcher and Julie Secombe},
  year={2011},
  url={https://api.semanticscholar.org/CorpusID:262247896}
}

@misc{lepennec_2023, 
  title={Ggwordcloud: A word cloud geom for ggplot2}, 
  year={2023},
  url={https://lepennec.github.io/ggwordcloud/articles/ggwordcloud.html}, 
  journal={lepennec.github.io/ggwordcloud/}, 
  author={le Pennec, E.}
  } 

@article{mehl_etal_2006,
  title={Personality in its natural habitat: manifestations and implicit folk theories of personality in daily life.},
  author={Matthias R. Mehl and Samuel D. Gosling and James W. Pennebaker},
  journal={Journal of personality and social psychology},
  year={2006},
  volume={90 5},
  pages={862-77},
  url={https://api.semanticscholar.org/CorpusID:2932332}
}

@article{michel_etal_2011,
author = {Jean-Baptiste Michel  and Yuan Kui Shen  and Aviva Presser Aiden  and Adrian Veres  and Matthew K. Gray  and The Google Books Team and Joseph P. Pickett  and Dale Hoiberg  and Dan Clancy  and Peter Norvig  and Jon Orwant  and Steven Pinker  and Martin A. Nowak  and Erez Lieberman Aiden },
title = {Quantitative Analysis of Culture Using Millions of Digitized Books},
journal = {Science},
volume = {331},
number = {6014},
pages = {176-182},
year = {2011},
doi = {10.1126/science.1199644},
URL = {https://www.science.org/doi/abs/10.1126/science.1199644},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1199644},
abstract = {Linguistic and cultural changes are revealed through the analyses of words appearing in books. We constructed a corpus of digitized texts containing about 4\% of all books ever printed. Analysis of this corpus enables us to investigate cultural trends quantitatively. We survey the vast terrain of ‘culturomics,’ focusing on linguistic and cultural phenomena that were reflected in the English language between 1800 and 2000. We show how this approach can provide insights about fields as diverse as lexicography, the evolution of grammar, collective memory, the adoption of technology, the pursuit of fame, censorship, and historical epidemiology. Culturomics extends the boundaries of rigorous quantitative inquiry to a wide array of new phenomena spanning the social sciences and the humanities.}
}

@article{mooijman_etal_2018,
  title={Moralization in social networks and the emergence of violence during protests},
  author={Marlon Mooijman and Joe Hoover and Ying Lin and Heng Ji and Morteza Dehghani},
  journal={Nature Human Behaviour},
  year={2018},
  volume={2},
  pages={389 - 396},
  url={https://doi.org/10.1038/s41562-018-0353-0}
}

@article{pennebaker_etal_1999,
  title={Linguistic styles: language use as an individual difference.},
  author={Pennebaker, James W and King, Laura A},
  journal={Journal of personality and social psychology},
  volume={77},
  number={6},
  pages={1296},
  year={1999},
  publisher={American Psychological Association},
  url={https://doi.org/10.1037//0022-3514.77.6.1296}
}

@article{schwartz_etal_2013,
    doi = {10.1371/journal.pone.0073791},
    author = {Schwartz, H. andrew and Eichstaedt, Johannes C. and Kern, Margaret L. and Dziurzynski, Lukasz and Ramones, Stephanie M. and Agrawal, Megha and Shah, Achal and Kosinski, Michal and Stillwell, David and Seligman, Martin E. P. and Ungar, Lyle H.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Personality, Gender, and Age in the Language of Social Media: The Open-Vocabulary Approach},
    year = {2013},
    month = {09},
    volume = {8},
    url = {https://doi.org/10.1371/journal.pone.0073791},
    pages = {1-16},
    abstract = {We analyzed 700 million words, phrases, and topic instances collected from the Facebook messages of 75,000 volunteers, who also took standard personality tests, and found striking variations in language with personality, gender, and age. In our open-vocabulary technique, the data itself drives a comprehensive exploration of language that distinguishes people, finding connections that are not captured with traditional closed-vocabulary word-category analyses. Our analyses shed new light on psychosocial processes yielding results that are face valid (e.g., subjects living in high elevations talk about the mountains), tie in with other research (e.g., neurotic people disproportionately use the phrase ‘sick of’ and the word ‘depressed’), suggest new hypotheses (e.g., an active life implies emotional stability), and give detailed insights (males use the possessive ‘my’ when mentioning their ‘wife’ or ‘girlfriend’ more often than females use ‘my’ with ‘husband’ or 'boyfriend’). To date, this represents the largest study, by an order of magnitude, of language and personality.},
    number = {9},
}

@article{schwartz_ungar_2015,
author = {H. andrew Schwartz and Lyle H. Ungar},
title ={Data-Driven Content Analysis of Social Media: A Systematic Overview of Automated Methods},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {78-94},
year = {2015},
doi = {10.1177/0002716215569197},
URL = {https://doi.org/10.1177/0002716215569197},
eprint = {https://doi.org/10.1177/0002716215569197},
abstract = { Researchers have long measured people’s thoughts, feelings, and personalities using carefully designed survey questions, which are often given to a relatively small number of volunteers. The proliferation of social media, such as Twitter and Facebook, offers alternative measurement approaches: automatic content coding at unprecedented scales and the statistical power to do open-vocabulary exploratory analysis. We describe a range of automatic and partially automatic content analysis techniques and illustrate how their use on social media generates insights into subjective well-being, health, gender differences, and personality.}
}

@article{simchon_etal_2020,
  title={Political depression? A big-data, multimethod investigation of Americans' emotional response to the Trump presidency.},
  author={Almog Simchon and Sharath Chandra Guntuku and Rotem Simhon and Lyle H. Ungar and Ran R. Hassin and Michael Gilead},
  journal={Journal of experimental psychology. General},
  year={2020},
  url={https://doi.org/10.1037/xge0000767}
}

@article{simchon_etal_2021,
title = {Beyond doubt in a dangerous world: The effect of existential threats on the certitude of societal discourse},
journal = {Journal of Experimental Social Psychology},
volume = {97},
pages = {104221},
year = {2021},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2021.104221},
url = {https://www.sciencedirect.com/science/article/pii/S0022103121001244},
author = {Almog Simchon and Chaya Turkin and Tal Svoray and Itai Kloog and Michael Dorman and Michael Gilead},
keywords = {Big data, Terror management theory, Emotion, Social discourse, Motivated reasoning},
abstract = {What happens when entire populations are exposed to news of impending existential threats? In the current study, we address this question by investigating the association between existential threats and the certitude of societal discourse. According to appraisal theory, threats give rise to anxiety and perceptions of uncertainty; as such, it predicts that exposure to life-threatening events will increase expressions of uncertainty. An alternative possibility is that people will respond to threats by utilizing psychological compensation mechanisms that will give rise to greater expressions of certainty. Across two studies, we measured linguistic certainty in more than 3.2 million tweets, covering different psychological contexts: (i) the 15 major terrorist and school shooting events that took place between 2016 and 2018; (ii) the COVID-19 pandemic. Consistent with the idea of compensatory processing, the results show that levels of expressed certainty increased following intentional and natural existential threats. We discuss the implications of our findings to theories of psychological compensation and to our understanding of collective response in the age of global threats.}
}

@article{sumner_etal_2011,
author = {Sumner, Chris and Byers, Alison and Shearing, Matthew},
year = {2011},
month = {01},
pages = {},
title = {Determining personality traits & privacy concerns from Facebook activity},
volume = {11},
journal = {Black Hat brief}
}


@article{tausczik_pennebaker_2010,
author = {Yla R. Tausczik and James W. Pennebaker},
title ={The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods},
journal = {Journal of Language and Social Psychology},
volume = {29},
number = {1},
pages = {24-54},
year = {2010},
doi = {10.1177/0261927X09351676},
URL = {https://doi.org/10.1177/0261927X09351676},
eprint = {https://doi.org/10.1177/0261927X09351676},
abstract = { We are in the midst of a technological revolution whereby, for the first time, researchers can link daily word use to a broad array of real-world behaviors. This article reviews several computerized text analysis methods and describes how Linguistic Inquiry and Word Count (LIWC) was created and validated. LIWC is a transparent text analysis program that counts words in psychologically meaningful categories. Empirical results using LIWC demonstrate its ability to detect meaning in a wide variety of experimental settings, including to show attentional focus, emotionality, social relationships, thinking styles, and individual differences. }
}

@book{wilkinson_2005,
author = {Wilkinson, Leland},
title = {The Grammar of Graphics (Statistics and Computing)},
year = {2005},
doi = {10.5555/1088896},
isbn = {0387245448},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@inproceedings{zamani_etal_2018,
    title = "Predicting Human Trustfulness from {F}acebook Language",
    author = "Zamani, Mohammadzaman  and
      Buffone, Anneke  and
      Schwartz, H. andrew",
    editor = "Loveys, Kate  and
      Niederhoffer, Kate  and
      Prud{'}hommeaux, Emily  and
      Resnik, Rebecca  and
      Resnik, Philip",
    booktitle = "Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic",
    month = jun,
    year = "2018",
    address = "New Orleans, LA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-0619",
    doi = "10.18653/v1/W18-0619",
    pages = "174--181",
    abstract = "Trustfulness {---} one{'}s general tendency to have confidence in unknown people or situations {---} predicts many important real-world outcomes such as mental health and likelihood to cooperate with others such as clinicians. While data-driven measures of interpersonal trust have previously been introduced, here, we develop the first language-based assessment of the personality trait of trustfulness by fitting one{'}s language to an accepted questionnaire-based trust score. Further, using trustfulness as a type of case study, we explore the role of questionnaire size as well as word count in developing language-based predictive models of users{'} psychological traits. We find that leveraging a longer questionnaire can yield greater test set accuracy, while, for training, we find it beneficial to include users who took smaller questionnaires which offers more observations for training. Similarly, after noting a decrease in individual prediction error as word count increased, we found a word count-weighted training scheme was helpful when there were very few users in the first place.",
}