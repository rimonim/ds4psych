@inproceedings{adamic_etal_2005,
  author = {Adamic, Lada A. and Glance, Natalie},
  title = {The Political Blogosphere and the 2004 U.S. Election: Divided They Blog},
  year = {2005},
  isbn = {1595932151},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1134271.1134277},
  doi = {10.1145/1134271.1134277},
  abstract = {In this paper, we study the linking patterns and discussion topics of political bloggers. Our aim is to measure the degree of interaction between liberal and conservative blogs, and to uncover any differences in the structure of the two communities. Specifically, we analyze the posts of 40 "A-list" blogs over the period of two months preceding the U.S. Presidential Election of 2004, to study how often they referred to one another and to quantify the overlap in the topics they discussed, both within the liberal and conservative communities, and also across communities. We also study a single day snapshot of over 1,000 political blogs. This snapshot captures blogrolls (the list of links to other blogs frequently found in sidebars), and presents a more static picture of a broader blogosphere. Most significantly, we find differences in the behavior of liberal and conservative blogs, with conservative blogs linking to each other more frequently and in a denser pattern.},
  booktitle = {Proceedings of the 3rd International Workshop on Link Discovery},
  pages = {36–43},
  numpages = {8},
  keywords = {social networks, political blogs, link analysis},
  location = {Chicago, Illinois},
  series = {LinkKDD '05}
}

@misc{alammar_2019, 
  title={The Illustrated Word2vec}, 
  url={http://jalammar.github.io/illustrated-word2vec/}, 
  journal={Jay Alammar – Visualizing machine learning one concept at a time}, 
  author={Alammar, Jay},
  year={2019}
} 

@article{anderson_etal_1991,
  author = {Anne H. Anderson and Miles Bader and Ellen Gurman Bard and Elizabeth Boyle and Gwyneth Doherty and Simon Garrod and Stephen Isard and Jacqueline Kowtko and Jan McAllister and Jim Miller and Catherine Sotillo and Henry S. Thompson and Regina Weinert},
  title = {The HCRC Map Task Corpus},
  journal = {Language and Speech},
  volume = {34},
  number = {4},
  pages = {351-366},
  year = {1991},
  doi = {10.1177/002383099103400404},
  URL = {https://doi.org/10.1177/002383099103400404},
  eprint = {https://doi.org/10.1177/002383099103400404},
  abstract = { This paper describes a corpus of unscripted, task-oriented dialogues which has been designed, digitally recorded, and transcribed to support the study of spontaneous speech on many levels. The corpus uses the Map Task (Brown, Anderson, Yule, and Shillcock, 1983) in which speakers must collaborate verbally to reproduce on one participant's map a route printed on the other's. In all, the corpus includes four conversations from each of 64 young adults and manipulates the following variables: familiarity of speakers, eye contact between speakers, matching between landmarks on the participants' maps, opportunities for contrastive stress, and phonological characteristics of landmark names. The motivations for the design are set out and basic corpus statistics are presented. }
}


@article{ashokkumar_pennebaker_2022,
    author = {Ashokkumar, Ashwini and Pennebaker, James W},
    title = {Tracking group identity through natural language within groups},
    journal = {PNAS Nexus},
    volume = {1},
    number = {2},
    pages = {pgac022},
    year = {2022},
    month = {06},
    abstract = {To what degree can we determine people's connections with groups through the language they use? In recent years, large archives of behavioral data from social media communities have become available to social scientists, opening the possibility of tracking naturally occurring group identity processes. A feature of most digital groups is that they rely exclusively on the written word. Across 3 studies, we developed and validated a language-based metric of group identity strength and demonstrated its potential in tracking identity processes in online communities. In Studies 1a–1c, 873 people wrote about their connections to various groups (country, college, or religion). A total of 2 language markers of group identity strength were found: high affiliation (more words like we, togetherness) and low cognitive processing or questioning (fewer words like think, unsure). Using these markers, a language-based unquestioning affiliation index was developed and applied to in-class stream-of-consciousness essays of 2,161 college students (Study 2). Greater levels of unquestioning affiliation expressed in language predicted not only self-reported university identity but also students’ likelihood of remaining enrolled in college a year later. In Study 3, the index was applied to naturalistic Reddit conversations of 270,784 people in 2 online communities of supporters of the 2016 presidential candidates—Hillary Clinton and Donald Trump. The index predicted how long people would remain in the group (3a) and revealed temporal shifts mirroring members’ joining and leaving of groups (3b). Together, the studies highlight the promise of a language-based approach for tracking and studying group identity processes in online groups.},
    issn = {2752-6542},
    doi = {10.1093/pnasnexus/pgac022},
    url = {https://doi.org/10.1093/pnasnexus/pgac022},
    eprint = {https://academic.oup.com/pnasnexus/article-pdf/1/2/pgac022/47087259/pgac022.pdf},
}

@proceedings{baumgartner_etal_2020,
  author = {Baumgartner, Jason and Zannettou, Savvas and Keegan, Brian and Squire, Megan and Blackburn, Jeremy},
  title = {The Pushshift Reddit Dataset},
  year = 2020,
  publisher = {Zenodo},
  month = jan,
  doi = {10.5281/zenodo.3608135},
  url = {https://doi.org/10.5281/zenodo.3608135}
}

@article{biester_etal_2022,
    doi = {10.1371/journal.pone.0278179},
    author = {Biester, Laura and Pennebaker, James and Mihalcea, Rada},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Emotional and cognitive changes surrounding online depression identity claims},
    year = {2022},
    month = {12},
    volume = {17},
    url = {https://doi.org/10.1371/journal.pone.0278179},
    pages = {1-20},
    abstract = {As social media has proliferated, a key aspect to making meaningful connections with people online has been revealing important parts of one’s identity. In this work, we study changes that occur in people’s language use after they share a specific piece of their identity: a depression diagnosis. To do so, we collect data from over five thousand users who have made such a statement, which we refer to as an identity claim. Prior to making a depression identity claim, the Reddit user’s language displays evidence of increasingly higher rates of anxiety, sadness, and cognitive processing language compared to matched controls. After the identity claim, these language markers decrease and more closely match the controls. Similarly, first person singular pronoun usage decreases following the identity claim, which was previously previously found to be indicative of self-focus and associated with depression. By further considering how and to whom people express their identity, we find that the observed longitudinal changes are larger for those who do so in ways that are more correlated with seeking help (sharing in a post instead of a comment; sharing in a mental health support forum). This work suggests that there may be benefits to sharing one’s depression diagnosis, especially in a semi-anonymous forum where others are likely to be empathetic.},
    number = {12},

}

@article{buechel_etal_2018,
  author       = {Sven Buechel and
                  Anneke Buffone and
                  Barry Slaff and
                  Lyle H. Ungar and
                  Jo{\~{a}}o Sedoc},
  title        = {Modeling Empathy and Distress in Reaction to News Stories},
  journal      = {CoRR},
  volume       = {abs/1808.10399},
  year         = {2018},
  url          = {http://arxiv.org/abs/1808.10399},
  eprinttype    = {arXiv},
  eprint       = {1808.10399},
  timestamp    = {Mon, 03 Sep 2018 13:36:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1808-10399.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{burger_etal_2011,
author = {Burger, John D. and Henderson, John and Kim, George and Zarrella, Guido},
title = {Discriminating Gender on Twitter},
year = {2011},
isbn = {9781937284114},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.},
booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {1301–1309},
numpages = {9},
location = {Edinburgh, United Kingdom},
series = {EMNLP '11}
}

@article{chersoni_etal_2021,
  title = {Decoding Word Embeddings with Brain-Based Semantic Features},
  author = {Chersoni, Emmanuele and Santus, Enrico  and Huang, Chu-Ren and Lenci, Alessandro},
  journal = {Computational Linguistics},
  volume = {47},
  number = {3},
  month = nov,
  year = {2021},
  address = {Cambridge, MA},
  publisher = {MIT Press},
  url = {https://aclanthology.org/2021.cl-3.20},
  doi = {10.1162/coli_a_00412},
  pages = {663--698}.
  abstract = {Word embeddings are vectorial semantic representations built with either counting or predicting techniques aimed at capturing shades of meaning from word co-occurrences. Since their introduction, these representations have been criticized for lacking interpretable dimensions. This property of word embeddings limits our understanding of the semantic features they actually encode. Moreover, it contributes to the {``}black box{''} nature of the tasks in which they are used, since the reasons for word embedding performance often remain opaque to humans. In this contribution, we explore the semantic properties encoded in word embeddings by mapping them onto interpretable vectors, consisting of explicit and neurobiologically motivated semantic features (Binder et al. 2016). Our exploration takes into account different types of embeddings, including factorized count vectors and predict models (Skip-Gram, GloVe, etc.), as well as the most recent contextualized representations (i.e., ELMo and BERT). In our analysis, we first evaluate the quality of the mapping in a retrieval task, then we shed light on the semantic features that are better encoded in each embedding type. A large number of probing tasks is finally set to assess how the original and the mapped embeddings perform in discriminating semantic categories. For each probing task, we identify the most relevant semantic features and we show that there is a correlation between the embedding performance and how they encode those features. This study sets itself as a step forward in understanding which aspects of meaning are captured by vector spaces, by proposing a new and simple method to carve human-interpretable semantic representations from distributional vectors.}.
}

@article{chung_pennebaker_2008,
title = {Revealing dimensions of thinking in open-ended self-descriptions: An automated meaning extraction method for natural language},
journal = {Journal of Research in Personality},
volume = {42},
number = {1},
pages = {96-132},
year = {2008},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2007.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0092656607000451},
author = {Cindy K. Chung and James W. Pennebaker},
keywords = {LIWC, Meaning extraction method, Natural language, Self-descriptions},
abstract = {A new method for extracting common themes from written text is introduced and applied to 1165 open-ended self-descriptive narratives. Drawing on a lexical approach to personality, the most commonly-used adjectives within narratives written by college students were identified using computerized text analytic tools. A factor analysis on the use of these adjectives in the self-descriptions produced a 7-factor solution consisting of psychologically meaningful dimensions. Some dimensions were unipolar (e.g., Negativity factor, wherein most loaded items were negatively valenced adjectives); others were dimensional in that semantically opposite words clustered together (e.g., Sociability factor, wherein terms such as shy, outgoing, reserved, and loud all loaded in the same direction). The factors exhibited modest reliability across different types of writing samples and were correlated with self-reports and behaviors consistent with the dimensions. Similar analyses with additional content words (adjectives, adverbs, nouns, and verbs) yielded additional psychological dimensions associated with physical appearance, school, relationships, etc. in which people contextualize their self-concepts. The results suggest that the meaning extraction method is a promising strategy that determines the dimensions along which people think about themselves.}
}

@inproceedings{cohan_etal_2018,
    title = {{SMHD}: a Large-Scale Resource for Exploring Online Language Usage for Multiple Mental Health Conditions}.
    author = {Cohan, Arman  and
      Desmet, Bart  and
      Yates, Andrew  and
      Soldaini, Luca  and
      MacAvaney, Sean  and
      Goharian, Nazli}.
    editor = {Bender, Emily M.  and
      Derczynski, Leon  and
      Isabelle, Pierre}.
    booktitle = {Proceedings of the 27th International Conference on Computational Linguistics}.
    month = aug,
    year = {2018}.
    address = {Santa Fe, New Mexico, USA}.
    publisher = {Association for Computational Linguistics}.
    url = {https://aclanthology.org/C18-1126}.
    pages = {1485--1497}.
    abstract = {Mental health is a significant and growing public health concern. As language usage can be leveraged to obtain crucial insights into mental health conditions, there is a need for large-scale, labeled, mental health-related datasets of users who have been diagnosed with one or more of such conditions. In this paper, we investigate the creation of high-precision patterns to identify self-reported diagnoses of nine different mental health conditions, and obtain high-quality labeled data without the need for manual labelling. We introduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it available. SMHD is a novel large dataset of social media posts from users with one or multiple mental health conditions along with matched control users. We examine distinctions in users{'} language, as measured by linguistic and psychological variables. We further explore text classification methods to identify individuals with mental conditions through their language.}.
}

@article{dideriksen_etal_2023, 
  author = {Dideriksen, C. and Christiansen, M. H. and Tylén, K. and Dingemanse, M. and Fusaroli, R.}, 
  title = {Quantifying the interplay of conversational devices in building mutual understanding.}, 
  journal = {Journal of Experimental Psychology: General}, 
  year = {2023}, 
  volume = {152}, 
  issue = {3}, 
  pages = {864-889}, 
  doi = {10.1037/xge0001301} 
}

@inproceedings{dingemanse_liesenfeld_2022,
    title = {From text to talk: {H}arnessing conversational corpora for humane and diversity-aware language technology}.
    author = {Dingemanse, Mark  and
      Liesenfeld, andreas}.
    editor = {Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline}.
    booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}.
    month = may,
    year = {2022}.
    address = {Dublin, Ireland}.
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2022.acl-long.385},
    doi = {10.18653/v1/2022.acl-long.385},
    pages = {5614--5633},
    abstract = {Informal social interaction is the primordial home of human language. Linguistically diverse conversational corpora are an important and largely untapped resource for computational linguistics and language technology. Through the efforts of a worldwide language documentation movement, such corpora are increasingly becoming available. We show how interactional data from 63 languages (26 families) harbours insights about turn-taking, timing, sequential structure and social action, with implications for language technology, natural language understanding, and the design of conversational interfaces. Harnessing linguistically diverse conversational corpora will provide the empirical foundations for flexible, localizable, humane language technologies of the future.},
}

@article{davies_2009,
  title={The 385+ million word Corpus of Contemporary American English (1990―2008+): Design, architecture, and linguistic insights},
  author={Mark Davies},
  journal={International Journal of Corpus Linguistics},
  year={2009},
  volume={14},
  pages={159-190},
  url={https://www.english-corpora.org//coca/}
}

@article{deerwester_etal_1990,
  title={Indexing by Latent Semantic Analysis},
  authors={Scott Deerwester and Susan T. Dumais and George W. Furnas and Thomas K. Landauer and Richard A. Harshman},
  journal={Journal of the Association for Information Science and Technology},
  year={1990},
  publisher={John Wiley & Sons, Ltd},
  volume={41},
  pages={391-407},
  number={6},
  doi={10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9},  
}

@article{downs_etal_2017,
  title={Detection of Suicidality in Adolescents with Autism Spectrum Disorders: Developing a Natural Language Processing Approach for Use in Electronic Health Records},
  author={Johnny M Downs and Sumithra Velupillai and George Gkotsis and Rachel Holden and Maxim Kikoler and Harry Dean and andrea C. Fernandes and Rina Dutta},
  journal={AMIA ... Annual Symposium proceedings. AMIA Symposium},
  year={2017},
  volume={2017},
  pages={
          641-649
        },
  url={https://api.semanticscholar.org/CorpusID:7388358}
}

@article{eichstaedt_etal_2015,
author = {Johannes C. Eichstaedt and Hansen andrew Schwartz and Margaret L. Kern and Gregory Park and Darwin R. Labarthe and Raina M. Merchant and Sneha Jha and Megha Agrawal and Lukasz A. Dziurzynski and Maarten Sap and Christopher Weeg and Emily E. Larson and Lyle H. Ungar and Martin E. P. Seligman},
title ={Psychological Language on Twitter Predicts County-Level Heart Disease Mortality},
journal = {Psychological Science},
volume = {26},
number = {2},
pages = {159-169},
year = {2015},
doi = {10.1177/0956797614557867},
note ={PMID: 25605707},
URL = {https://osf.io/rt6w2/},
eprint = {https://doi.org/10.1177/0956797614557867},
abstract = { Hostility and chronic stress are known risk factors for heart disease, but they are costly to assess on a large scale. We used language expressed on Twitter to characterize community-level psychological correlates of age-adjusted mortality from atherosclerotic heart disease (AHD). Language patterns reflecting negative social relationships, disengagement, and negative emotions—especially anger—emerged as risk factors; positive emotions and psychological engagement emerged as protective factors. Most correlations remained significant after controlling for income and education. A cross-sectional regression model based only on Twitter language predicted AHD mortality significantly better than did a model that combined 10 common demographic, socioeconomic, and health risk factors, including smoking, diabetes, hypertension, and obesity. Capturing community psychological characteristics through social media is feasible, and these characteristics are strong markers of cardiovascular mortality at the community level. }
}

@article{gagne_etal_2005,
  author = {Gagné, Christina and Spalding, Thomas and Ji, Hongbo},
  year = {2005},
  month = {09},
  pages = {445-455},
  title = {Re-examining evidence for the use of independent relational representations during conceptual combination},
  volume = {53},
  journal = {Journal of Memory and Language},
  doi = {10.1016/j.jml.2005.03.006}
}

@article{garcia_sikstrom_2013,
  author={Danilo Garcia and Sverker Sikström},
  title={{Quantifying the Semantic Representations of Adolescents’ Memories of Positive and Negative Life Events}},
  journal={Journal of Happiness Studies},
  year=2013,
  volume={14},
  number={4},
  pages={1309-1323},
  month={August},
  keywords={Quantitative semantic; Adolescence; Affect; Autobiographical memory; Happiness; Latent semantic anal},
  doi={10.1007/s10902-012-9385-8},
  abstract={We quantified the semantic content in adolescents’ descriptions of positive and negative life events and studied how these descriptions are related to the assessment subjective well-being (SWB) at two points in time. The semantic content of the descriptions was quantified by latent semantic analysis (LSA). LSA is a computational method based on algorithms stemming from computational linguistics, where a high dimensional semantic representation of words can be generated from co-occurrence of words in huge text corpora. We investigated if the semantic content of written autobiographical memories of positive and negative life events predicted traditionally ranked measures of SWB, i.e., self-reports of Positive and Negative Affect, and thus created semantic measures of SWB. Such measures can be used to investigate the relationship between semantic content and SWB, which could only indirectly be accomplished by the ranked data. Pupils wrote down positive or negative life events during the last 3 months and self-reported SWB. Four weeks later, participants were presented with their own description and asked to report current SWB. The results showed that the semantic representation predicted SWB and experimental conditions. The agreement between semantic and ranked measures supports the validity of the semantic scores. We argue that our proposed method for studying SWB provides new and essential information about well-being by the quantification of a richer set of information from adolescents’ own memories. Copyright Springer Science+Business Media B.V. 2013},
  url={https://ideas.repec.org/a/spr/jhappi/v14y2013i4p1309-1323.html}
}

@article{golder_macy_2011,
author = {Scott A. Golder  and Michael W. Macy },
title = {Diurnal and Seasonal Mood Vary with Work, Sleep, and Daylength Across Diverse Cultures},
journal = {Science},
volume = {333},
number = {6051},
pages = {1878-1881},
year = {2011},
doi = {10.1126/science.1202775},
URL = {https://www.science.org/doi/abs/10.1126/science.1202775},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1202775},
abstract = {Across the world the collective mood heightens
at breakfast time and during the weekend. We identified individual-level diurnal and seasonal mood rhythms in cultures across the globe, using data from millions of public Twitter messages. We found that individuals awaken in a good mood that deteriorates as the day progresses—which is consistent with the effects of sleep and circadian rhythm—and that seasonal change in baseline positive affect varies with change in daylength. People are happier on weekends, but the morning peak in positive affect is delayed by 2 hours, which suggests that people awaken later on weekends.}
}

@article{gunther_etal_2019,
  author = {Fritz Günther and Luca Rinaldi and Marco Marelli},
  title ={Vector-Space Models of Semantic Representation From a Cognitive Perspective: A Discussion of Common Misconceptions},
  journal = {Perspectives on Psychological Science},
  volume = {14},
  number = {6},
  pages = {1006-1033},
  year = {2019},
  doi = {10.1177/1745691619861372},
  note ={PMID: 31505121},
  URL = {https://doi.org/10.1177/1745691619861372},
  eprint = {https://doi.org/10.1177/1745691619861372},
  abstract = { Models that represent meaning as high-dimensional numerical vectors—such as latent semantic analysis (LSA), hyperspace analogue to language (HAL), bound encoding of the aggregate language environment (BEAGLE), topic models, global vectors (GloVe), and word2vec—have been introduced as extremely powerful machine-learning proxies for human semantic representations and have seen an explosive rise in popularity over the past 2 decades. However, despite their considerable advancements and spread in the cognitive sciences, one can observe problems associated with the adequate presentation and understanding of some of their features. Indeed, when these models are examined from a cognitive perspective, a number of unfounded arguments tend to appear in the psychological literature. In this article, we review the most common of these arguments and discuss (a) what exactly these models represent at the implementational level and their plausibility as a cognitive theory, (b) how they deal with various aspects of meaning such as polysemy or compositionality, and (c) how they relate to the debate on embodied and grounded cognition. We identify common misconceptions that arise as a result of incomplete descriptions, outdated arguments, and unclear distinctions between theory and implementation of the models. We clarify and amend these points to provide a theoretical basis for future research and discussions on vector models of semantic representation. }
}

@article{hellman_2011,
abstract = {This study investigated whether adult‐onset second language (L2) learners achieve native level vocabulary after decades of immersion. Vocabulary tests were given to three groups of participants: highly successful adult‐onset learners of English, monolingual English speakers, and bilingual native speakers of English. Overall, the native speakers outperformed the non‐native speakers; however, the rate of native like achievement was remarkably high among the successful adult‐onset learners, which indicated that native level L2 vocabulary size and depth of word knowledge were attainable in adulthood. Factors that correlated with native level L2 vocabulary were: childhood caregivers' education, verbal ability and literacy in the native language, and interest in word learning and daily reading. The findings suggest that the lexicon may be the potentially most successful area of adult‐onset L2 learning.},
author = {Hellman, Andrea B.},
address = {Oxford, UK},
copyright = {2010 Blackwell Publishing Ltd},
issn = {0802-6106},
journal = {International journal of applied linguistics},
keywords = {adult language learning ; angol nyelv ; bilingualism ; Foreign language learning ; idegennyelv tanulás ; Language acquisition ; lexical development ; native vs. non-native speakers ; nyelvoktatás ; second language acquisition ; szókincs ; szókincsfelmérés ; vocabulary ; Vocabulary development},
language = {eng},
number = {2},
pages = {162-182},
publisher = {Blackwell Publishing Ltd},
title = {Vocabulary size and depth of word knowledge in adult-onset second language acquisition},
volume = {21},
year = {2011},
}

@article{holtgraves_2011,
title = {Text messaging, personality, and the social context},
journal = {Journal of Research in Personality},
volume = {45},
number = {1},
pages = {92-99},
year = {2011},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2010.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0092656610001698},
author = {Thomas Holtgraves},
keywords = {Texting, Language, Personality, Language use},
abstract = {The purpose of this research was to undertake some analyses of how the language used in text messaging varies as a function of personality traits and the interpersonal context. After completing personality questionnaires, participants provided their most recent text messages and indicated their relationship with the message recipient on several dimensions. Correlations between Linguistic Inquiry and Word Count (LIWC) categories and personality traits and relationship status were examined. There were significant correlations between certain LIWC categories and extraversion (e.g., personal pronouns), neuroticism (e.g., negative emotion words) and agreeableness (e.g., positive emotion words), suggesting that personality traits are displayed in how one texts. One of the defining features of texting – linguistic alterations (e.g., abbreviations) – varied as a function of both personality traits and relationship status. Overall, the results provide a snapshot of what text messages look like, and how they reflect the texter’s personality and the interpersonal context.}
}

@inproceedings{hovy_spruit_2016,
    title = {The Social Impact of Natural Language Processing},
    author = {Hovy, Dirk and Spruit, Shannon L.},
    editor = {Erk, Katrin  and Smith, Noah A.},
    booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
    month = aug,
    year = {2016},
    address = {Berlin, Germany},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/P16-2096},
    doi = {10.18653/v1/P16-2096},
    pages = {591--598},
}

@inbook{kennedy_etal_2022,
author = {Brendan Kennedy and Ashwini Ashokkumar and Boyd, {Ryan L} and Morteza Dehghani},
title = {Text Analysis for Psychology: Methods, Principles, and Practices},
year = {2022},
month = jan,
day = {7},
pages = {3-64},
language = {English},
isbn = {9781462548439},
editor = {Morteza Dehghani and Boyd, {Ryan L}},
booktitle = {Handbook of Language Analysis in Psychology},
publisher = {Guilford Press},
}

@article{kessler_2017,
  author    = {Kessler, Jason S.},
  title     = {Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ},
  booktitle = {Proceedings of ACL-2017 System Demonstrations},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  URL = {https://github.com/JasonKessler/scattertext}
}

@misc{kjell_etal_2021,
 title={The text-package: An R-package for Analyzing and Visualizing Human Language Using Natural Language Processing and Deep Learning},
 url={osf.io/preprints/psyarxiv/293kt},
 DOI={10.31234/osf.io/293kt},
 publisher={PsyArXiv},
 author={Kjell, Oscar N E and Giorgi, Salvatore and Schwartz, H. A},
 year={2021},
 month={Apr}
}

@article{kjell_etal_2022,
author = {Kjell, Oscar and Sikström, Sverker and Kjell, Katarina and Schwartz, H.},
year = {2022},
month = {03},
pages = {3918},
title = {Natural language analyzed with AI-based transformers predict traditional subjective well-being measures approaching the theoretical upper limits in accuracy},
volume = {12},
journal = {Scientific Reports},
doi = {10.1038/s41598-022-07520-w}
}

@article{kosinski_etal_2013,
author = {Michal Kosinski  and David Stillwell  and Thore Graepel },
title = {Private traits and attributes are predictable from digital records of human behavior},
journal = {Proceedings of the National Academy of Sciences},
volume = {110},
number = {15},
pages = {5802-5805},
year = {2013},
doi = {10.1073/pnas.1218772110},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1218772110},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1218772110},
abstract = {We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88\% of cases, African Americans and Caucasian Americans in 95\% of cases, and between Democrat and Republican in 85\% of cases. For the personality trait “Openness,” prediction accuracy is close to the test–retest accuracy of a standard personality test. We give examples of associations between attributes and Likes and discuss implications for online personalization and privacy.}
}

@article{kozlowski_etal_2019,
author = {Austin C. Kozlowski and Matt Taddy and James A. Evans},
title ={The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings},
journal = {American Sociological Review},
volume = {84},
number = {5},
pages = {905-949},
year = {2019},
doi = {10.1177/0003122419877135},
URL = {https://doi.org/10.1177/0003122419877135},
eprint = {https://doi.org/10.1177/0003122419877135},
abstract = { We argue word embedding models are a useful tool for the study of culture using a historical analysis of shared understandings of social class as an empirical case. Word embeddings represent semantic relations between words as relationships between vectors in a high-dimensional space, specifying a relational model of meaning consistent with contemporary theories of culture. Dimensions induced by word differences (rich – poor) in these spaces correspond to dimensions of cultural meaning, and the projection of words onto these dimensions reflects widely shared associations, which we validate with surveys. Analyzing text from millions of books published over 100 years, we show that the markers of class continuously shifted amidst the economic transformations of the twentieth century, yet the basic cultural dimensions of class remained remarkably stable. The notable exception is education, which became tightly linked to affluence independent of its association with cultivated taste. }
}

@article{kulkarni_etal_2018,
doi = {10.1371/journal.pone.0201703},
author = {Kulkarni, Vivek and Kern, Margaret L. and Stillwell, David and Kosinski, Michal and Matz, Sandra and Ungar, Lyle and Skiena, Steven and Schwartz, H. andrew},
journal = {PLOS ONE},
publisher = {Public Library of Science},
title = {Latent human traits in the language of social media: An open-vocabulary approach},
year = {2018},
month = {11},
volume = {13},
url = {https://doi.org/10.1371/journal.pone.0201703},
pages = {1-18},
abstract = {Over the past century, personality theory and research has successfully identified core sets of characteristics that consistently describe and explain fundamental differences in the way people think, feel and behave. Such characteristics were derived through theory, dictionary analyses, and survey research using explicit self-reports. The availability of social media data spanning millions of users now makes it possible to automatically derive characteristics from behavioral data—language use—at large scale. Taking advantage of linguistic information available through Facebook, we study the process of inferring a new set of potential human traits based on unprompted language use. We subject these new traits to a comprehensive set of evaluations and compare them with a popular five factor model of personality. We find that our language-based trait construct is often more generalizable in that it often predicts non-questionnaire-based outcomes better than questionnaire-based traits (e.g. entities someone likes, income and intelligence quotient), while the factors remain nearly as stable as traditional factors. Our approach suggests a value in new constructs of personality derived from everyday human language use.},
number = {11},
}

@article{lazer_etal_2014,
author = {David Lazer  and Ryan Kennedy  and Gary King  and Alessandro Vespignani },
title = {The Parable of Google Flu: Traps in Big Data Analysis},
journal = {Science},
volume = {343},
number = {6176},
pages = {1203-1205},
year = {2014},
doi = {10.1126/science.1248506},
URL = {https://www.science.org/doi/abs/10.1126/science.1248506},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1248506},
abstract = {Large errors in flu prediction were largely avoidable, which offers lessons for the use of big data. In February 2013, Google Flu Trends (GFT) made headlines but not for a reason that Google executives or the creators of the flu tracking system would have hoped. Nature reported that GFT was predicting more than double the proportion of doctor visits for influenza-like illness (ILI) than the Centers for Disease Control and Prevention (CDC), which bases its estimates on surveillance reports from laboratories across the United States (1, 2). This happened despite the fact that GFT was built to predict CDC reports. Given that GFT is often held up as an exemplary use of big data (3, 4), what lessons can we draw from this error?}}

@article{lazer_etal_2009,
author = {David Lazer  and Alex Pentland  and Lada Adamic  and Sinan Aral  and Albert-László Barabási  and Devon Brewer  and Nicholas Christakis  and Noshir Contractor  and James Fowler  and Myron Gutmann  and Tony Jebara  and Gary King  and Michael Macy  and Deb Roy  and Marshall Van Alstyne },
title = {Computational Social Science},
journal = {Science},
volume = {323},
number = {5915},
pages = {721-723},
year = {2009},
doi = {10.1126/science.1167742},
URL = {https://www.science.org/doi/abs/10.1126/science.1167742},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1167742}
}

@inproceedings{le_etal_2011,
  title={Diurnal and Seasonal Mood Vary with Work, Sleep, and Daylength Across Diverse Cultures},
  author={Hiep D. Le and Christopher Vollmers and Megumi Hatori and Michael Witcher and Julie Secombe},
  year={2011},
  url={https://api.semanticscholar.org/CorpusID:262247896}
}

@misc{lepennec_2023, 
  title={Ggwordcloud: A word cloud geom for ggplot2}, 
  year={2023},
  url={https://lepennec.github.io/ggwordcloud/articles/ggwordcloud.html}, 
  journal={lepennec.github.io/ggwordcloud/}, 
  author={le Pennec, E.}
  } 

@inproceedings{levy_goldberg_2014,
 author = {Levy, Omer and Goldberg, Yoav},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Neural Word Embedding as Implicit Matrix Factorization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf},
 volume = {27},
 year = {2014}
}

@article{mehl_etal_2006,
  title={Personality in its natural habitat: manifestations and implicit folk theories of personality in daily life.},
  author={Matthias R. Mehl and Samuel D. Gosling and James W. Pennebaker},
  journal={Journal of personality and social psychology},
  year={2006},
  volume={90 5},
  pages={862-77},
  url={https://api.semanticscholar.org/CorpusID:2932332}
}

@article{michel_etal_2011,
author = {Jean-Baptiste Michel  and Yuan Kui Shen  and Aviva Presser Aiden  and Adrian Veres  and Matthew K. Gray  and The Google Books Team and Joseph P. Pickett  and Dale Hoiberg  and Dan Clancy  and Peter Norvig  and Jon Orwant  and Steven Pinker  and Martin A. Nowak  and Erez Lieberman Aiden },
title = {Quantitative Analysis of Culture Using Millions of Digitized Books},
journal = {Science},
volume = {331},
number = {6014},
pages = {176-182},
year = {2011},
doi = {10.1126/science.1199644},
URL = {https://www.science.org/doi/abs/10.1126/science.1199644},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1199644},
abstract = {Linguistic and cultural changes are revealed through the analyses of words appearing in books. We constructed a corpus of digitized texts containing about 4\% of all books ever printed. Analysis of this corpus enables us to investigate cultural trends quantitatively. We survey the vast terrain of ‘culturomics,’ focusing on linguistic and cultural phenomena that were reflected in the English language between 1800 and 2000. We show how this approach can provide insights about fields as diverse as lexicography, the evolution of grammar, collective memory, the adoption of technology, the pursuit of fame, censorship, and historical epidemiology. Culturomics extends the boundaries of rigorous quantitative inquiry to a wide array of new phenomena spanning the social sciences and the humanities.}
}

@inproceedings{mikolov_etal_2013,
  title = {Linguistic Regularities in Continuous Space Word Representations},
  author = {Mikolov, Tomas and Yih, Wen-tau and Zweig, Geoffrey},
  editor = {Vanderwende, Lucy  and
    Daum{\'e} III, Hal  and
    Kirchhoff, Katrin},
  booktitle = {Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month = jun,
  year = {2013},
  address = {Atlanta, Georgia},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/N13-1090},
  pages = {746--751},
}

@inproceedings{millet_etal_2022,
 author = {Millet, Juliette and Caucheteux, Charlotte and Orhan, Pierre and Boubenec, Yves and Gramfort, Alexandre and Dunbar, Ewan and Pallier, Christophe and King, Jean-Remi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {33428--33443},
 publisher = {Curran Associates, Inc.},
 title = {Toward a realistic model of speech processing in the brain with self-supervised learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/d81ecfc8fb18e833a3fa0a35d92532b8-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{mooijman_etal_2018,
  title={Moralization in social networks and the emergence of violence during protests},
  author={Marlon Mooijman and Joe Hoover and Ying Lin and Heng Ji and Morteza Dehghani},
  journal={Nature Human Behaviour},
  year={2018},
  volume={2},
  pages={389 - 396},
  url={https://doi.org/10.1038/s41562-018-0353-0}
}

@article{munoz_iglesias_2022,
title = {A text classification approach to detect psychological stress combining a lexicon-based feature framework with distributional representations},
journal = {Information Processing & Management},
volume = {59},
number = {5},
pages = {103011},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103011},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001212},
author = {Sergio Muñoz and Carlos A. Iglesias},
keywords = {Stress detection, Stress framework, Distributional representations, Text classification, Affective computing},
abstract = {Nowadays, stress has become a growing problem for society due to its high impact on individuals but also on health care systems and companies. In order to overcome this problem, early detection of stress is a key factor. Previous studies have shown the effectiveness of text analysis in the detection of sentiment, emotion, and mental illness. However, existing solutions for stress detection from text are focused on a specific corpus. There is still a lack of well-validated methods that provide good results in different datasets. We aim to advance state of the art by proposing a method to detect stress in textual data and evaluating it using multiple public English datasets. The proposed approach combines lexicon-based features with distributional representations to enhance classification performance. To help organize features for stress detection in text, we propose a lexicon-based feature framework that exploits affective, syntactic, social, and topic-related features. Also, three different word embedding techniques are studied for exploiting distributional representation. Our approach has been implemented with three machine learning models that have been evaluated in terms of performance through several experiments. This evaluation has been conducted using three public English datasets and provides a baseline for other researchers. The obtained results identify the combination of FastText embeddings with a selection of lexicon-based features as the best-performing model, achieving F-scores above 80%.}
}

@article{olteanu_etal_2016,
author = {Olteanu, Alexandra and Castillo, Carlos and Diaz, Fernando and Kiciman, Emre},
year = {2016},
month = {01},
pages = {},
title = {Social Data: Biases, Methodological Pitfalls, and Ethical Boundaries},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2886526}
}

@article{pennebaker_etal_1999,
  title={Linguistic styles: language use as an individual difference.},
  author={Pennebaker, James W and King, Laura A},
  journal={Journal of personality and social psychology},
  volume={77},
  number={6},
  pages={1296},
  year={1999},
  publisher={American Psychological Association},
  url={https://doi.org/10.1037//0022-3514.77.6.1296}
}

@inproceedings{pennington_etal_2014,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@article{proferes_etal_2021,
  author = {Nicholas Proferes and Naiyan Jones and Sarah Gilbert and Casey Fiesler and Michael Zimmer},
  title ={Studying Reddit: A Systematic Overview of Disciplines, Approaches, Methods, and Ethics},
  journal = {Social Media + Society},
  volume = {7},
  number = {2},
  pages = {20563051211019004},
  year = {2021},
  doi = {10.1177/20563051211019004},
  URL = {https://doi.org/10.1177/20563051211019004},
  eprint = {https://doi.org/10.1177/20563051211019004},
      abstract = { This article offers a systematic analysis of 727 manuscripts that used Reddit as a data source, published between 2010 and 2020. Our analysis reveals the increasing growth in use of Reddit as a data source, the range of disciplines this research is occurring in, how researchers are getting access to Reddit data, the characteristics of the datasets researchers are using, the subreddits and topics being studied, the kinds of analysis and methods researchers are engaging in, and the emerging ethical questions of research in this space. We discuss how researchers need to consider the impact of Reddit’s algorithms, affordances, and generalizability of the scientific knowledge produced using Reddit data, as well as the potential ethical dimensions of research that draws data from subreddits with potentially sensitive populations. }
}

@article{rosenbusch_etal_2019,
  author = {Hannes Rosenbusch and Anthony M. Evans and Marcel Zeelenberg},
  title ={Multilevel Emotion Transfer on YouTube: Disentangling the Effects of Emotional Contagion and Homophily on Video Audiences},
  journal = {Social Psychological and Personality Science},
  volume = {10},
  number = {8},
  pages = {1028-1035},
  year = {2019},
  doi = {10.1177/1948550618820309},
  URL = {https://doi.org/10.1177/1948550618820309},
  eprint = {https://doi.org/10.1177/1948550618820309},
  abstract = { Why do connected users in online social networks express similar emotions? Past approaches have suggested situational emotion transfers (i.e., contagion) and the phenomenon that emotionally similar users flock together (i.e., homophily). We analyze these mechanisms in unison by exploiting the hierarchical structure of YouTube through multilevel analyses, disaggregating the video- and channel-level effects of YouTuber emotions on audience comments. Dictionary analyses using the National Research Council emotion lexica were used to measure the emotions expressed in videos and user comments from 2,083 YouTube vlogs selected from 110 vloggers. We find that video- and channel-level emotions independently influence audience emotions, providing evidence for both contagion and homophily effects. Random slope models suggest that contagion strength varies between YouTube channels for some emotions. However, neither average channel-level emotions nor number of subscribers significantly moderate the strength of contagion effects. The present study highlights that multiple, independent mechanisms shape emotions in online social networks. }
}

@article{sap_etal_2022,
author = {Maarten Sap  and Anna Jafarpour  and Yejin Choi  and Noah A. Smith  and James W. Pennebaker  and Eric Horvitz },
title = {Quantifying the narrative flow of imagined versus autobiographical stories},
journal = {Proceedings of the National Academy of Sciences},
volume = {119},
number = {45},
pages = {e2211715119},
year = {2022},
doi = {10.1073/pnas.2211715119},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2211715119},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2211715119},
abstract = {Lifelong experiences and learned knowledge lead to shared expectations about how common situations tend to unfold. Such knowledge of narrative event flow enables people to weave together a story. However, comparable computational tools to evaluate the flow of events in narratives are limited. We quantify the differences between autobiographical and imagined stories by introducing sequentiality, a measure of narrative flow of events, drawing probabilistic inferences from a cutting-edge large language model (GPT-3). Sequentiality captures the flow of a narrative by comparing the probability of a sentence with and without its preceding story context. We applied our measure to study thousands of diary-like stories, collected from crowdworkers, about either a recent remembered experience or an imagined story on the same topic. The results show that imagined stories have higher sequentiality than autobiographical stories and that the sequentiality of autobiographical stories increases when the memories are retold several months later. In pursuit of deeper understandings of how sequentiality measures the flow of narratives, we explore proportions of major and minor events in story sentences, as annotated by crowdworkers. We find that lower sequentiality is associated with higher proportions of major events. The methods and results highlight opportunities to use cutting-edge computational analyses, such as sequentiality, on large corpora of matched imagined and autobiographical stories to investigate the influences of memory and reasoning on language generation processes.}
}

@inproceedings{sap_etal_2020,
    title = {Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models},
    author = {Sap, Maarten  and
      Horvitz, Eric  and
      Choi, Yejin  and
      Smith, Noah A.  and
      Pennebaker, James},
    editor = {Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel},
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    month = jul,
    year = {2020},
    address = {Online},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2020.acl-main.178},
    doi = {10.18653/v1/2020.acl-main.178},
    pages = {1970--1978},
    abstract = {We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release Hippocorpus, a dataset of 7,000 stories about imagined and recalled events. We introduce a measure of narrative flow and use this to examine the narratives for imagined and recalled events. Additionally, we measure the differential recruitment of knowledge attributed to semantic memory versus episodic memory (Tulving, 1972) for imagined and recalled storytelling by comparing the frequency of descriptions of general commonsense events with more specific realis events. Our analyses show that imagined stories have a substantially more linear narrative flow, compared to recalled stories in which adjacent sentences are more disconnected. In addition, while recalled stories rely more on autobiographical events based on episodic memory, imagined stories express more commonsense knowledge based on semantic memory. Finally, our measures reveal the effect of narrativization of memories in stories (e.g., stories about frequently recalled memories flow more linearly; Bartlett, 1932). Our findings highlight the potential of using NLP tools to study the traces of human cognition in language.},
}

@inproceedings{schler_etal_2006,
author = {Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James},
year = {2006},
month = {01},
pages = {199-205},
title = {Effects of Age and Gender on Blogging.}
}

@article{schwartz_etal_2013,
    doi = {10.1371/journal.pone.0073791},
    author = {Schwartz, H. andrew and Eichstaedt, Johannes C. and Kern, Margaret L. and Dziurzynski, Lukasz and Ramones, Stephanie M. and Agrawal, Megha and Shah, Achal and Kosinski, Michal and Stillwell, David and Seligman, Martin E. P. and Ungar, Lyle H.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Personality, Gender, and Age in the Language of Social Media: The Open-Vocabulary Approach},
    year = {2013},
    month = {09},
    volume = {8},
    url = {https://doi.org/10.1371/journal.pone.0073791},
    pages = {1-16},
    abstract = {We analyzed 700 million words, phrases, and topic instances collected from the Facebook messages of 75,000 volunteers, who also took standard personality tests, and found striking variations in language with personality, gender, and age. In our open-vocabulary technique, the data itself drives a comprehensive exploration of language that distinguishes people, finding connections that are not captured with traditional closed-vocabulary word-category analyses. Our analyses shed new light on psychosocial processes yielding results that are face valid (e.g., subjects living in high elevations talk about the mountains), tie in with other research (e.g., neurotic people disproportionately use the phrase ‘sick of’ and the word ‘depressed’), suggest new hypotheses (e.g., an active life implies emotional stability), and give detailed insights (males use the possessive ‘my’ when mentioning their ‘wife’ or ‘girlfriend’ more often than females use ‘my’ with ‘husband’ or 'boyfriend’). To date, this represents the largest study, by an order of magnitude, of language and personality.},
    number = {9},
}

@article{schwartz_ungar_2015,
author = {H. andrew Schwartz and Lyle H. Ungar},
title ={Data-Driven Content Analysis of Social Media: A Systematic Overview of Automated Methods},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {78-94},
year = {2015},
doi = {10.1177/0002716215569197},
URL = {https://doi.org/10.1177/0002716215569197},
eprint = {https://doi.org/10.1177/0002716215569197},
abstract = { Researchers have long measured people’s thoughts, feelings, and personalities using carefully designed survey questions, which are often given to a relatively small number of volunteers. The proliferation of social media, such as Twitter and Facebook, offers alternative measurement approaches: automatic content coding at unprecedented scales and the statistical power to do open-vocabulary exploratory analysis. We describe a range of automatic and partially automatic content analysis techniques and illustrate how their use on social media generates insights into subjective well-being, health, gender differences, and personality.}
}

@article{simchon_etal_2020,
  title={Political depression? A big-data, multimethod investigation of Americans' emotional response to the Trump presidency.},
  author={Almog Simchon and Sharath Chandra Guntuku and Rotem Simhon and Lyle H. Ungar and Ran R. Hassin and Michael Gilead},
  journal={Journal of experimental psychology. General},
  year={2020},
  url={https://doi.org/10.1037/xge0000767}
}

@article{simchon_etal_2021,
title = {Beyond doubt in a dangerous world: The effect of existential threats on the certitude of societal discourse},
journal = {Journal of Experimental Social Psychology},
volume = {97},
pages = {104221},
year = {2021},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2021.104221},
url = {https://www.sciencedirect.com/science/article/pii/S0022103121001244},
author = {Almog Simchon and Chaya Turkin and Tal Svoray and Itai Kloog and Michael Dorman and Michael Gilead},
keywords = {Big data, Terror management theory, Emotion, Social discourse, Motivated reasoning},
abstract = {What happens when entire populations are exposed to news of impending existential threats? In the current study, we address this question by investigating the association between existential threats and the certitude of societal discourse. According to appraisal theory, threats give rise to anxiety and perceptions of uncertainty; as such, it predicts that exposure to life-threatening events will increase expressions of uncertainty. An alternative possibility is that people will respond to threats by utilizing psychological compensation mechanisms that will give rise to greater expressions of certainty. Across two studies, we measured linguistic certainty in more than 3.2 million tweets, covering different psychological contexts: (i) the 15 major terrorist and school shooting events that took place between 2016 and 2018; (ii) the COVID-19 pandemic. Consistent with the idea of compensatory processing, the results show that levels of expressed certainty increased following intentional and natural existential threats. We discuss the implications of our findings to theories of psychological compensation and to our understanding of collective response in the age of global threats.}
}

@misc{stillwell_kosinski_2015,  
title={myPersonality Project website},  
author={Stillwell, DJ and Kosinski, M}, 
year={2015}
}

@article{sumner_etal_2011,
author = {Sumner, Chris and Byers, Alison and Shearing, Matthew},
year = {2011},
month = {01},
pages = {},
title = {Determining personality traits & privacy concerns from Facebook activity},
volume = {11},
journal = {Black Hat brief}
}


@article{tausczik_pennebaker_2010,
author = {Yla R. Tausczik and James W. Pennebaker},
title ={The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods},
journal = {Journal of Language and Social Psychology},
volume = {29},
number = {1},
pages = {24-54},
year = {2010},
doi = {10.1177/0261927X09351676},
URL = {https://doi.org/10.1177/0261927X09351676},
eprint = {https://doi.org/10.1177/0261927X09351676},
abstract = { We are in the midst of a technological revolution whereby, for the first time, researchers can link daily word use to a broad array of real-world behaviors. This article reviews several computerized text analysis methods and describes how Linguistic Inquiry and Word Count (LIWC) was created and validated. LIWC is a transparent text analysis program that counts words in psychologically meaningful categories. Empirical results using LIWC demonstrate its ability to detect meaning in a wide variety of experimental settings, including to show attentional focus, emotionality, social relationships, thinking styles, and individual differences. }
}

@article{utsumi_2020,
  title={Exploring What Is Encoded in Distributional Word Vectors: A Neurobiologically Motivated Analysis},
  author={Akira Utsumi},
  journal={Cognitive science},
  year={2020},
  volume={44 6},
  pages={e12844},
  url={https://api.semanticscholar.org/CorpusID:218911983}
}

@book{wilkinson_2005,
author = {Wilkinson, Leland},
title = {The Grammar of Graphics (Statistics and Computing)},
year = {2005},
doi = {10.5555/1088896},
isbn = {0387245448},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@InProceedings{xiao_mensah_2022,
  author={Xiao, Lu and Mensah, Humphrey},
  editor={Arai, Kohei},
  title={How Does the Thread Level of a Comment Affect its Perceived Persuasiveness? A Reddit Study},
  booktitle={Intelligent Computing},
  year={2022},
  publisher={Springer International Publishing},
  pages={800--813},
  abstract={Online interactions increasingly involve complex processes of persuasion and influence. Compared to the long history and richness of persuasion studies in traditional communication settings, we have limited understanding of how people are influenced by others in online communications and how persuasion works in online environments. While it is common in online discussions that some comments are threaded under a specific thread, it is un-known whether and how the thread level affects its perceived persuasiveness. To explore this research inquiry, we collected and analyzed threaded discussions in Reddit's r/changemyview context. We found that the perceived persuasiveness of a comment fluctuates systematically from the top thread level to the most nested level. We conducted a semantic similarity analysis among adjacent comments in the threads examining how similar the comments are with respect to their content. Our results suggest that the first thread comment brings up a new idea or perspective, and the next comment matures it by adding new information to elaborate it, therefore, this comment is more likely to receive a delta point than the first comment. Additionally, this pattern continues onto the next comments. Implying that there is a common reasoning pattern in engaging in the threaded discussions in Reddit r/changemyview, our study sheds light on a comprehensive understanding of online participants' reasoning behavior in threaded discussions.},
  isbn={978-3-031-10464-0}
}

@inproceedings{zamani_etal_2018,
    title = {Predicting Human Trustfulness from {F}acebook Language},
    author = {Zamani, Mohammadzaman  and
      Buffone, Anneke  and
      Schwartz, H. andrew},
    editor = {Loveys, Kate  and
      Niederhoffer, Kate  and
      Prud{'}hommeaux, Emily  and
      Resnik, Rebecca  and
      Resnik, Philip},
    booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic},
    month = jun,
    year = {2018},
    address = {New Orleans, LA},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/W18-0619},
    doi = {10.18653/v1/W18-0619},
    pages = {174--181},
    abstract = {Trustfulness {---} one{'}s general tendency to have confidence in unknown people or situations {---} predicts many important real-world outcomes such as mental health and likelihood to cooperate with others such as clinicians. While data-driven measures of interpersonal trust have previously been introduced, here, we develop the first language-based assessment of the personality trait of trustfulness by fitting one{'}s language to an accepted questionnaire-based trust score. Further, using trustfulness as a type of case study, we explore the role of questionnaire size as well as word count in developing language-based predictive models of users{'} psychological traits. We find that leveraging a longer questionnaire can yield greater test set accuracy, while, for training, we find it beneficial to include users who took smaller questionnaires which offers more observations for training. Similarly, after noting a decrease in individual prediction error as word count increased, we found a word count-weighted training scheme was helpful when there were very few users in the first place.},
}