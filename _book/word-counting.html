<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Louis Teitelbaum and Almog Simchon">
<title>Data Science for Psychology: Natural Language - 14&nbsp; Dictionary-Based Word Counts</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./dla.html" rel="next">
<link href="./tokenization.html" rel="prev">
<link href="./images/favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./quantification.html">Quantifying Psychological Properties of Text</a></li><li class="breadcrumb-item"><a href="./word-counting.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dictionary-Based Word Counts</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science for Psychology: Natural Language</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/rimonim/ds4psych" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=%7Curl%7C">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
</div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction: Why Does Psychology Need Natural Language?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Ethics of Data Science in Psychology</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./data-viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Visualization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./aesthetics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Why Aesthetic Choices are Important</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./telling-a-story.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Don’t Distract From the Story</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./word-viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Visualizing Distributions of Words</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data-viz-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Additional Resources for Data Visualization</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./data-sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sources of Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./corpora.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Corpus Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./apis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Web APIs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./scraping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Web Scraping</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./quantification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantifying Psychological Properties of Text</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./look-at-your-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Look at Your Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quanteda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction to Quanteda</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tokenization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Tokenization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./word-counting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dictionary-Based Word Counts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dla.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Open Vocabulary Word Counting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./word-counting-improvements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Transforming Word Counts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vectorspace-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction to Vector Space</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decontextualized-embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Word Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contextualized-embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Contextualization With Large Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./navigating-vectorspace.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Navigating Vector Space</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Topic Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linguistic-complexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Measures of Linguistic Complexity</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./querying_llms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Just Ask an LLM</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./audio-video-image.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Audio, Video, and Image Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transcription.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Transcribing Audio</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Additional Resources</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#sec-quanteda-dictionaries" id="toc-sec-quanteda-dictionaries" class="nav-link active" data-scroll-target="#sec-quanteda-dictionaries"><span class="header-section-number">14.1</span> Dictionaries</a></li>
  <li>
<a href="#sec-understand-your-dictionary" id="toc-sec-understand-your-dictionary" class="nav-link" data-scroll-target="#sec-understand-your-dictionary"><span class="header-section-number">14.2</span> Understand Your Dictionary</a>
  <ul class="collapse">
<li><a href="#how-was-your-dictionary-constructed" id="toc-how-was-your-dictionary-constructed" class="nav-link" data-scroll-target="#how-was-your-dictionary-constructed"><span class="header-section-number">14.2.1</span> How Was Your Dictionary Constructed?</a></li>
  <li><a href="#how-context-dependent-are-the-words-in-your-dictionary" id="toc-how-context-dependent-are-the-words-in-your-dictionary" class="nav-link" data-scroll-target="#how-context-dependent-are-the-words-in-your-dictionary"><span class="header-section-number">14.2.2</span> How Context-Dependent are the Words in Your Dictionary?</a></li>
  </ul>
</li>
  <li>
<a href="#raw-word-counts" id="toc-raw-word-counts" class="nav-link" data-scroll-target="#raw-word-counts"><span class="header-section-number">14.3</span> Raw Word Counts</a>
  <ul class="collapse">
<li><a href="#sec-modeling-word-counts" id="toc-sec-modeling-word-counts" class="nav-link" data-scroll-target="#sec-modeling-word-counts"><span class="header-section-number">14.3.1</span> Modeling Raw Word Counts</a></li>
  </ul>
</li>
  <li>
<a href="#sec-polarity" id="toc-sec-polarity" class="nav-link" data-scroll-target="#sec-polarity"><span class="header-section-number">14.4</span> Polarity</a>
  <ul class="collapse">
<li><a href="#modeling-polarity" id="toc-modeling-polarity" class="nav-link" data-scroll-target="#modeling-polarity"><span class="header-section-number">14.4.1</span> Modeling Polarity</a></li>
  </ul>
</li>
  <li>
<a href="#sec-word-scoring" id="toc-sec-word-scoring" class="nav-link" data-scroll-target="#sec-word-scoring"><span class="header-section-number">14.5</span> Lexical Norms</a>
  <ul class="collapse">
<li><a href="#modeling-norms" id="toc-modeling-norms" class="nav-link" data-scroll-target="#modeling-norms"><span class="header-section-number">14.5.1</span> Modeling Norms</a></li>
  </ul>
</li>
  <li>
<a href="#sec-dictionary-sources" id="toc-sec-dictionary-sources" class="nav-link" data-scroll-target="#sec-dictionary-sources"><span class="header-section-number">14.6</span> Sources of Dictionaries</a>
  <ul class="collapse">
<li><a href="#crowdsourced-dictionaries" id="toc-crowdsourced-dictionaries" class="nav-link" data-scroll-target="#crowdsourced-dictionaries"><span class="header-section-number">14.6.1</span> Crowdsourced Dictionaries</a></li>
  <li><a href="#expert-generated-dictionaries" id="toc-expert-generated-dictionaries" class="nav-link" data-scroll-target="#expert-generated-dictionaries"><span class="header-section-number">14.6.2</span> Expert-Generated Dictionaries</a></li>
  <li><a href="#corpus-based-dictionaries" id="toc-corpus-based-dictionaries" class="nav-link" data-scroll-target="#corpus-based-dictionaries"><span class="header-section-number">14.6.3</span> Corpus-Based Dictionaries</a></li>
  <li><a href="#other-approaches-to-dictionary-generation" id="toc-other-approaches-to-dictionary-generation" class="nav-link" data-scroll-target="#other-approaches-to-dictionary-generation"><span class="header-section-number">14.6.4</span> Other Approaches to Dictionary Generation</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/rimonim/ds4psych/blob/main/word-counting.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rimonim/ds4psych/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./quantification.html">Quantifying Psychological Properties of Text</a></li><li class="breadcrumb-item"><a href="./word-counting.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dictionary-Based Word Counts</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-word-counting" class="quarto-section-identifier"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dictionary-Based Word Counts</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>In <a href="tokenization.html" class="quarto-xref"><span>Chapter 13</span></a>, we transformed our corpus into a DFM with counts of each word in each document. But not all words are created equal; some words are much more psychologically interesting than others. The simplest way to count relevant words while ignoring others is by using a <strong>dictionary</strong>.</p>
<p>This chapter introduces the basics of dictionary-based methodology. <a href="dla.html" class="quarto-xref"><span>Chapter 15</span></a> and <a href="word-counting-improvements.html" class="quarto-xref"><span>Chapter 16</span></a> will build on this chapter, exploring more advanced ways to use token counting for measurement.</p>
<section id="sec-quanteda-dictionaries" class="level2" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="sec-quanteda-dictionaries">
<span class="header-section-number">14.1</span> Dictionaries</h2>
<p>A dictionary is a list of words (or other tokens) associated with a given psychological or other construct. For example, a dictionary for depression might include words like “sleepy” and “down.” We can use the dictionary to count construct-related words in each text—texts that use more construct-related words are then assumed to be more construct-related overall.</p>
<p>Let’s give a more concrete example: Recall that in the <em>Hippocorpus</em> data, the <code>memType</code> variable indicates whether the participant was told to tell a story that happened to them recently (“recalled”), a story that they had already told a few months earlier (“retold”), or an entirely fictional story (“imagined”).</p>
<p><span class="citation" data-cites="sap_etal_2022">Sap et al. (<a href="#ref-sap_etal_2022" role="doc-biblioref">2022</a>)</span> hypothesized that true autobiographical stories would include more surprising events than imagined stories. To test this hypothesis, we could use a dictionary of surprise-related words. Where could we find such a dictionary? Perhaps we could try making one up?</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">surprise_dict</span> <span class="op">&lt;-</span> <span class="fu">dictionary</span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>      surprise <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"surprise"</span>, <span class="st">"wow"</span>, <span class="st">"suddenly"</span>, <span class="st">"bang"</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="va">surprise_dict</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; Dictionary object with 1 key entry.
#&gt; - [surprise]:
#&gt;   - surprise, wow, suddenly, bang</code></pre>
</div>
</div>
<p>Generating a sentiment dictionary is not easy. Luckily, other researchers have done the work for us: The NRC Word-Emotion Association Lexicon <span class="citation" data-cites="mohammad_turney_2010 mohammad_turney_2013">(<a href="#ref-mohammad_turney_2013" role="doc-biblioref">S. M. Mohammad &amp; Turney, 2013</a>; <a href="#ref-mohammad_turney_2010" role="doc-biblioref">S. Mohammad &amp; Turney, 2010</a>)</span>, included in the <code>quanteda.sentiment</code> package, has a list of 534 surprise words.</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">surprise_dict</span> <span class="op">&lt;-</span> <span class="fu">quanteda.sentiment</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/quanteda.sentiment/man/data_dictionary_NRC.html">data_dictionary_NRC</a></span><span class="op">[</span><span class="st">"surprise"</span><span class="op">]</span></span>
<span><span class="va">surprise_dict</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; Dictionary object with 1 key entry.
#&gt; Polarities: pos = "positive"; neg = "negative" 
#&gt; - [surprise]:
#&gt;   - abandonment, abduction, abrupt, accident, accidental, accidentally, accolade, advance, affront, aghast, alarm, alarming, alertness, alerts, allure, amaze, amazingly, ambush, angel, anomaly [ ... and 514 more ]</code></pre>
</div>
</div>
<p>The NRC Word-Emotion Association Lexicon is a <strong>crowdsourced dictionary</strong>; <span class="citation" data-cites="mohammad_turney_2013">S. M. Mohammad &amp; Turney (<a href="#ref-mohammad_turney_2013" role="doc-biblioref">2013</a>)</span> generated it by presenting individual words to thousands of online participants and asking them to rate how much each word is “associated with the emotion surprise.” The final dictionary includes all the words that were consistently reported to be at least moderately associated with surprise.</p>
</section><section id="sec-understand-your-dictionary" class="level2" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="sec-understand-your-dictionary">
<span class="header-section-number">14.2</span> Understand Your Dictionary</h2>
<p>In <a href="look-at-your-data.html" class="quarto-xref"><span>Chapter 11</span></a>, we emphasized the importance of reading through your data before conducting any analyses. The same is true for dictionaries: Before using any dictionary-based methods, always look through your dictionary and ask yourself two questions:</p>
<ul>
<li>How was my dictionary constructed?</li>
<li>How context-dependent are the words in my dictionary?</li>
</ul>
<p>Let’s expand on each of these questions.</p>
<section id="how-was-your-dictionary-constructed" class="level3" data-number="14.2.1"><h3 data-number="14.2.1" class="anchored" data-anchor-id="how-was-your-dictionary-constructed">
<span class="header-section-number">14.2.1</span> How Was Your Dictionary Constructed?</h3>
<p>The surprise dictionary we are using was generated by asking participants how much each word was “associated with the emotion surprise” <span class="citation" data-cites="mohammad_turney_2013">(<a href="#ref-mohammad_turney_2013" role="doc-biblioref">S. M. Mohammad &amp; Turney, 2013</a>)</span>. A word can be “associated with” surprise because it reflects surprise (e.g.&nbsp;“suddenly”), but it can also be “associated with” surprise because it reflects the exact opposite of surprise. Indeed, if we <strong>look through the dictionary</strong>, we find words like “leisure” and “lovely”.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">surprise_dict</span><span class="op">$</span><span class="va">surprise</span>, <span class="fl">20</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt;  [1] "outburst"    "godsend"     "alarming"    "intense"     "lawsuit"    
#&gt;  [6] "leisure"     "scrimmage"   "curiosity"   "reappear"    "placard"    
#&gt; [11] "diversion"   "receiving"   "thirst"      "lovely"      "frenetic"   
#&gt; [16] "perfection"  "playground"  "fearfully"   "guess"       "unfulfilled"</code></pre>
</div>
</div>
<p>This means that we are not, in fact, measuring how surprising each story is. At best, we are measuring how much each story deals with surprise (or lack thereof) one way or another.</p>
<p>As you look through your dictionary, make sure you are aware of the process used to construct the dictionary. If it was generated by asking participants about individual words, how was the question formulated? How might that question have been interpreted by the participants?</p>
</section><section id="how-context-dependent-are-the-words-in-your-dictionary" class="level3" data-number="14.2.2"><h3 data-number="14.2.2" class="anchored" data-anchor-id="how-context-dependent-are-the-words-in-your-dictionary">
<span class="header-section-number">14.2.2</span> How Context-Dependent are the Words in Your Dictionary?</h3>
<p>The participants generating our dictionary were asked about one word at a time. People presented words out of context often fail to consider how words are actually used in natural discourse. For example, imagine that you are an online participant, and you are asked about your associations with the word “guess”. Seeing “guess” by itself might sound like an imperative, calling to mind a situation in which someone is asking you to guess something about which you are unsure—perhaps a game show. Since this sort of situation generally results in a surprise when the truth is revealed, you report that “guess” is associated with surprise. In fact, though, “guess” is <em>much</em> more frequently used in the phrase “I guess”, which signifies reluctance and has very little to do with surprise. We can check how “guess” is used our corpus by using Quanteda’s <code><a href="https://quanteda.io/reference/kwic.html">kwic()</a></code> function, which gives a dataframe of Key Words In Context (KIWC).</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">hippocorpus_tokens</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">kwic</span><span class="op">(</span><span class="st">"guess"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>text <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">pre</span>, <span class="va">keyword</span>, <span class="va">post</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">text</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; [1] "his 30th birthday and I guess that's why he decided to"            
#&gt; [2] "healthier after a month I guess it was the stress of"              
#&gt; [3] "already made cake So i guess it wasn't that bad"                   
#&gt; [4] "wrong Was she serious I guess so When I finished packing"          
#&gt; [5] "up our unit And I guess that's it I never saw"                     
#&gt; [6] "I'm not sure yet I guess I will see how the"                       
#&gt; [7] "FINALLY got admitted D I guess all those crazy contractions worked"
#&gt; [8] "we made it safely I guess even the car got tired"</code></pre>
</div>
</div>
<p>With the possible exception of #6, none of these examples give the impression of an impending surprise. Nevertheless, “guess” does appear in the NRC surprise dictionary.</p>
<p>As you look through your dictionary, think about how each word might really be used in context. Are there ways to use the word that do not have to do with your construct?</p>
</section></section><section id="raw-word-counts" class="level2" data-number="14.3"><h2 data-number="14.3" class="anchored" data-anchor-id="raw-word-counts">
<span class="header-section-number">14.3</span> Raw Word Counts</h2>
<p>At this point, you might be pretty skeptical about using the NRC surprise dictionary to measure surprise. Even so, let’s try it out. To count how many times surprise words appear in each of our texts, we use the <code><a href="https://quanteda.io/reference/dfm_lookup.html">dfm_lookup()</a></code> function.</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">hippocorpus_surprise</span> <span class="op">&lt;-</span> <span class="va">hippocorpus_dfm</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dfm_lookup</span><span class="op">(</span><span class="va">surprise_dict</span><span class="op">)</span></span>
<span></span>
<span><span class="va">hippocorpus_surprise</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; Document-feature matrix of: 6,854 documents, 1 feature (5.09% sparse) and 6 docvars.
#&gt;                                 features
#&gt; docs                             surprise
#&gt;   32RIADZISTQWI5XIVG5BN0VMYFRS4U        2
#&gt;   3018Q3ZVOJCZJFDMPSFXATCQ4DARA2        0
#&gt;   3IRIK4HM3B6UQBC0HI8Q5TBJZLEC61        4
#&gt;   3018Q3ZVOJCZJFDMPSFXATCQG04RAI        3
#&gt;   3MTMREQS4W44RBU8OMP3XSK8NMJAWZ        4
#&gt;   3018Q3ZVOJCZJFDMPSFXATCQG06AR3        6
#&gt; [ reached max_ndoc ... 6,848 more documents ]</code></pre>
</div>
</div>
<section id="sec-modeling-word-counts" class="level3" data-number="14.3.1"><h3 data-number="14.3.1" class="anchored" data-anchor-id="sec-modeling-word-counts">
<span class="header-section-number">14.3.1</span> Modeling Raw Word Counts</h3>
<p>Recall that we wanted to test whether true autobiographical stories include more surprise than imagined stories. Now that we have counted the number of surprise words in each document, how do we test our hypothesis?</p>
<p>A good first step is to reattach the word counts to our original corpus. As we do this, we convert both to dataframes.</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">hippocorpus_surprise_df</span> <span class="op">&lt;-</span> <span class="va">hippocorpus_surprise</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">convert</span><span class="op">(</span><span class="st">"data.frame"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># convert to dataframe</span></span>
<span>  <span class="fu">right_join</span><span class="op">(</span></span>
<span>    <span class="va">hippocorpus_corp</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu">convert</span><span class="op">(</span><span class="st">"data.frame"</span><span class="op">)</span> <span class="co"># convert to dataframe</span></span>
<span>    <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It makes sense to control for the total number of words in each text, since longer texts have more opportunities to use surprise words<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. To count the total number of tokens in each text, we can use the <code><a href="https://quanteda.io/reference/ntoken.html">ntoken()</a></code> function on our DFM and add the result directly to the new dataframe.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">hippocorpus_surprise_df</span> <span class="op">&lt;-</span> <span class="va">hippocorpus_surprise_df</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>wc <span class="op">=</span> <span class="fu">ntoken</span><span class="op">(</span><span class="va">hippocorpus_dfm</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We are now ready for modeling! When your dependent variable is a count of words, we recommend using negative binomial regression, available in R with the <code>MASS</code> package<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. For extra sensitivity to the variable rates at which word frequencies grow with text length <span class="citation" data-cites="baayen_2001">(see <a href="#ref-baayen_2001" role="doc-biblioref">Baayen, 2001</a>)</span>, we include <code>wc</code> as a both a predictor and an offset <code>offset(log(wc))</code> in the regression (an offset is just a predictor with its parameter at 1). We use <code><a href="https://rdrr.io/r/base/Log.html">log()</a></code> to account for the fact that negative binomial regression links the predictors with the outcome variable through a log link. This means that including <code>offset(log(wc))</code> is equivalent to modeling the ratio of surprise words to total words (for a more detailed explanation of this dynamic, see the discussion <a href="https://stats.stackexchange.com/questions/307369/how-to-interpret-glm-and-ols-with-offset">here</a>).</p>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">surprise_mod</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glm.nb.html">glm.nb</a></span><span class="op">(</span><span class="va">surprise</span> <span class="op">~</span> <span class="va">memType</span> <span class="op">+</span> <span class="va">wc</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wc</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                             data <span class="op">=</span> <span class="va">hippocorpus_surprise_df</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">surprise_mod</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; 
#&gt; Call:
#&gt; MASS::glm.nb(formula = surprise ~ memType + wc + offset(log(wc)), 
#&gt;     data = hippocorpus_surprise_df, init.theta = 6.070929358, 
#&gt;     link = log)
#&gt; 
#&gt; Coefficients:
#&gt;                   Estimate Std. Error  z value Pr(&gt;|z|)    
#&gt; (Intercept)     -3.9065113  0.0258623 -151.050  &lt; 2e-16 ***
#&gt; memTyperecalled -0.0324360  0.0176595   -1.837  0.06625 .  
#&gt; memTyperetold   -0.0614152  0.0219399   -2.799  0.00512 ** 
#&gt; wc              -0.0008833  0.0000876  -10.082  &lt; 2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; (Dispersion parameter for Negative Binomial(6.0709) family taken to be 1)
#&gt; 
#&gt;     Null deviance: 7490.2  on 6853  degrees of freedom
#&gt; Residual deviance: 7370.5  on 6850  degrees of freedom
#&gt; AIC: 30997
#&gt; 
#&gt; Number of Fisher Scoring iterations: 1
#&gt; 
#&gt; 
#&gt;               Theta:  6.071 
#&gt;           Std. Err.:  0.270 
#&gt; 
#&gt;  2 x log-likelihood:  -30987.333</code></pre>
</div>
</div>
<p>Looking at the p-values for the coefficients, we see that there was no significant difference between recalled and imagined stories (p = 0.066). There was, however, a significant difference between <em>retold</em> and imagined stories, such that retold stories used fewer surprise words (p = 0.005).</p>
<p><strong>An example of using raw word counts in research:</strong> <span class="citation" data-cites="simchon_etal_2023">Simchon et al. (<a href="#ref-simchon_etal_2023" role="doc-biblioref">2023</a>)</span> collected Twitter activity over a three month period from over 2.7 million users. Using a dictionary, they then counted the number of passive auxiliary verbs (e.g.&nbsp;“they <strong>were</strong> analyzed”; “my homework <strong>will be</strong> completed”) in each user’s activity. They found that users with more followers (indicating higher social status) used much fewer passive auxiliary verbs, controlling for total word count.</p>
</section></section><section id="sec-polarity" class="level2" data-number="14.4"><h2 data-number="14.4" class="anchored" data-anchor-id="sec-polarity">
<span class="header-section-number">14.4</span> Polarity</h2>
<p>How can we improve our measurement of surprise? As we saw above, one problem with the dictionary approach is that a word might be associated with a construct because it reflects the opposite of that construct. One solution to this problem is to measure the ratio between the target dictionary and its opposite. In sentiment analysis, this approach is called <em>polarity</em>. Polarity is most commonly used to analyze the overall valence of a text by comparing positive words (e.g.&nbsp;“happy”, “great”) with negative words (e.g.&nbsp;“disappointed”, “terrible”). In principle though, we can use it to compare any sort of opposites.</p>
<p>What is the opposite of surprise? <span class="citation" data-cites="plutchik_1962">Plutchik (<a href="#ref-plutchik_1962" role="doc-biblioref">1962</a>)</span> argues that the opposite of surprise is <em>anticipation</em>. Luckily, the NRC Word-Emotion Association Lexicon also includes a dictionary of anticipation-associated words. Using this dictionary, we can measure how much a text is associated with surprise <em>as opposed to</em> anticipation.</p>
<p>Quanteda’s built-in function for polarity is <code><a href="https://rdrr.io/pkg/quanteda.sentiment/man/textstat_polarity.html">textstat_polarity()</a></code>. To use this function, we first have to set the “positive” and “negative” polarities of the dictionary, and then call <code><a href="https://rdrr.io/pkg/quanteda.sentiment/man/textstat_polarity.html">textstat_polarity()</a></code> on our DFM. By default, this outputs the log ratio of positive to negative counts for each document:</p>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">quanteda.sentiment</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>#&gt; 
#&gt; Attaching package: 'quanteda.sentiment'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>#&gt; The following object is masked from 'package:quanteda':
#&gt; 
#&gt;     data_dictionary_LSD2015</code></pre>
</div>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># subset dictionary</span></span>
<span><span class="va">surprise_anticipation_dict</span> <span class="op">&lt;-</span> <span class="va">data_dictionary_NRC</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"surprise"</span>, <span class="st">"anticipation"</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># set surprise and anticipation as polarity</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/quanteda.sentiment/man/polarity.html">polarity</a></span><span class="op">(</span><span class="va">surprise_anticipation_dict</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>pos <span class="op">=</span> <span class="st">"surprise"</span>, neg <span class="op">=</span> <span class="st">"anticipation"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># get polarity</span></span>
<span><span class="va">hippocorpus_surprise_polarity</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/quanteda.sentiment/man/textstat_polarity.html">textstat_polarity</a></span><span class="op">(</span><span class="va">hippocorpus_dfm</span>, <span class="va">surprise_anticipation_dict</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">rename</span><span class="op">(</span>surprise_vs_anticipation <span class="op">=</span> <span class="va">sentiment</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>While <code><a href="https://rdrr.io/pkg/quanteda.sentiment/man/textstat_polarity.html">textstat_polarity()</a></code> can sometimes be useful for visualizations or downstream analyses, it is not helpful for modeling polarity as an outcome variable.</p>
<section id="modeling-polarity" class="level3" data-number="14.4.1"><h3 data-number="14.4.1" class="anchored" data-anchor-id="modeling-polarity">
<span class="header-section-number">14.4.1</span> Modeling Polarity</h3>
<p>To test whether true autobiographical stories include more surprise <em>relative</em> to anticipation than imagined stories, we first count the surprise and anticipation words in each document, and rejoin the results to the full dataset.</p>
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># count surprise/anticipation words</span></span>
<span><span class="va">hippocorpus_surprise_anticipation</span> <span class="op">&lt;-</span> <span class="va">hippocorpus_dfm</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://quanteda.io/reference/dfm_lookup.html">dfm_lookup</a></span><span class="op">(</span><span class="va">surprise_anticipation_dict</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># convert to dataframe and join to full data</span></span>
<span><span class="va">hippocorpus_surprise_anticipation_df</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">hippocorpus_surprise_anticipation</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://quanteda.io/reference/convert.html">convert</a></span><span class="op">(</span><span class="st">"data.frame"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">right_join</span><span class="op">(</span></span>
<span>    <span class="va">hippocorpus_corp</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu"><a href="https://quanteda.io/reference/convert.html">convert</a></span><span class="op">(</span><span class="st">"data.frame"</span><span class="op">)</span> <span class="co"># convert to dataframe</span></span>
<span>    <span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>wc <span class="op">=</span> <span class="fu"><a href="https://quanteda.io/reference/ntoken.html">ntoken</a></span><span class="op">(</span><span class="va">hippocorpus_dfm</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>#&gt; Joining with `by = join_by(doc_id)`</code></pre>
</div>
</div>
<p>Since we are still modelling word counts as an output, we again use negative binomial regression. Rather than controlling for the total word count, however, we can control for the total number of surprise words plus the number of anticipation words. Because of the log link function (along with the endlessly useful properties of logarithms) entering this sum as a log offset (<code>offset(log(surprise + anticipation))</code>) is equivalent to modeling the ratio of surprise-related to anticipation-related words.</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># remove zeros to prevent divide by zero errors</span></span>
<span><span class="va">hippocorpus_surprise_anticipation_df</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">hippocorpus_surprise_anticipation_df</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">surprise</span> <span class="op">+</span> <span class="va">anticipation</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2024</span><span class="op">)</span></span>
<span><span class="va">surprise_anticipation_mod</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glm.nb.html">glm.nb</a></span><span class="op">(</span></span>
<span>  <span class="va">surprise</span> <span class="op">~</span> <span class="va">memType</span> <span class="op">+</span> <span class="va">wc</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">surprise</span> <span class="op">+</span> <span class="va">anticipation</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">hippocorpus_surprise_anticipation_df</span>,</span>
<span>  <span class="co"># increase iterations to ensure model converges</span></span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.control.html">glm.control</a></span><span class="op">(</span>maxit <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span> </span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">surprise_anticipation_mod</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; 
#&gt; Call:
#&gt; MASS::glm.nb(formula = surprise ~ memType + wc + offset(log(surprise + 
#&gt;     anticipation)), data = hippocorpus_surprise_anticipation_df, 
#&gt;     control = glm.control(maxit = 10000), init.theta = 2.949221746e+17, 
#&gt;     link = log)
#&gt; 
#&gt; Coefficients:
#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    
#&gt; (Intercept)     -1.107e+00  1.990e-02 -55.659   &lt;2e-16 ***
#&gt; memTyperecalled -1.128e-02  1.356e-02  -0.831    0.406    
#&gt; memTyperetold   -1.966e-02  1.697e-02  -1.158    0.247    
#&gt; wc              -5.675e-05  6.462e-05  -0.878    0.380    
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; (Dispersion parameter for Negative Binomial(2.949222e+17) family taken to be 1)
#&gt; 
#&gt;     Null deviance: 4884.6  on 6843  degrees of freedom
#&gt; Residual deviance: 4882.1  on 6840  degrees of freedom
#&gt; AIC: 10
#&gt; 
#&gt; Number of Fisher Scoring iterations: 1
#&gt; 
#&gt; 
#&gt;               Theta:  2.949222e+17 
#&gt;           Std. Err.:  6.158994e+14 
#&gt; 
#&gt;  2 x log-likelihood:  0</code></pre>
</div>
</div>
<p>There is no significant difference between true and imagined stories in the ratio of surprise to anticipation words.</p>
</section></section><section id="sec-word-scoring" class="level2" data-number="14.5"><h2 data-number="14.5" class="anchored" data-anchor-id="sec-word-scoring">
<span class="header-section-number">14.5</span> Lexical Norms</h2>
<p>So far we have covered raw word counts, which use one list of words to represent a construct, and we have covered polarities, which use two lists of words to represent a construct and its opposite. The third and final dictionary-based method takes a more nuanced approach than either of these: In lexical norms, words are allowed to represent the construct or its opposite to continuously varying degrees, represented by numbers on a scale. In <code>quanteda.sentiment</code>, this scale is called “valence”, though elsewhere it can be called “lexical affinity” or “lexical association”.</p>
<p>The same group that created the NRC Word-Emotion Association Lexicon also created a parallel dictionary with continuous scores: the <a href="https://saifmohammad.com/WebPages/AccessResource.htm">NRC Hashtag Emotion Lexicon</a> <span class="citation" data-cites="mohammad_kiritchenko_2015">(<a href="#ref-mohammad_kiritchenko_2015" role="doc-biblioref">S. M. Mohammad &amp; Kiritchenko, 2015</a>)</span>. Whereas the NRC Word-Emotion Association Lexicon was crowdsourced, the NRC Hashtag Emotion Lexicon was generated algorithmically from a corpus of Twitter posts which contained hashtags like “#anger” and “#surprise”. The dictionary includes the words that were most predictive of each hashtag, with scores indicating the strength of their statistical connection with the category (higher score indicates more representative). We can access the NRC Hashtag surprise dictionary from Github:</p>
<div class="cell">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">path</span> <span class="op">&lt;-</span> <span class="st">"https://raw.githubusercontent.com/bwang482/emotionannotate/master/lexicons/NRC-Hashtag-Emotion-Lexicon-v0.2.txt"</span></span>
<span></span>
<span><span class="va">hashtag</span> <span class="op">&lt;-</span> <span class="fu">read_tsv</span><span class="op">(</span><span class="va">path</span>, col_names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"emotion"</span>, <span class="st">"token"</span>, <span class="st">"score"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>#&gt; Rows: 32389 Columns: 3
#&gt; ── Column specification ────────────────────────────────────────────────────────
#&gt; Delimiter: "\t"
#&gt; chr (2): emotion, token
#&gt; dbl (1): score
#&gt; 
#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.
#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">hashtag</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">emotion</span> <span class="op">==</span> <span class="st">"surprise"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; # A tibble: 6 × 3
#&gt;   emotion  token         score
#&gt;   &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt;
#&gt; 1 surprise yada           1.49
#&gt; 2 surprise #preoccupied   1.49
#&gt; 3 surprise jaden          1.49
#&gt; 4 surprise #easilyamused  1.49
#&gt; 5 surprise #needtofocus   1.49
#&gt; 6 surprise #amazement     1.49</code></pre>
</div>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create dictionary</span></span>
<span><span class="va">surprise_dict_hashtag</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dictionary.html">dictionary</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>surprise <span class="op">=</span> <span class="va">hashtag</span><span class="op">$</span><span class="va">token</span><span class="op">[</span><span class="va">hashtag</span><span class="op">$</span><span class="va">emotion</span> <span class="op">==</span> <span class="st">"surprise"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set dictionary valence</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/quanteda.sentiment/man/valence.html">valence</a></span><span class="op">(</span><span class="va">surprise_dict_hashtag</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  surprise <span class="op">=</span> <span class="va">hashtag</span><span class="op">$</span><span class="va">score</span><span class="op">[</span><span class="va">hashtag</span><span class="op">$</span><span class="va">emotion</span> <span class="op">==</span> <span class="st">"surprise"</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To measure suprise in the Hippocorpus data, we find the suprise score of each token and compute the average score for the tokens of each document. With <code>quanteda.sentiment</code>, we can do this by calling the <code><a href="https://rdrr.io/pkg/quanteda.sentiment/man/textstat_valence.html">textstat_valence()</a></code> function on our DFM. Since a score of zero in the NRC Hashtag Emotion Lexicon represents zero surprise, we will add <code>normalization = "all"</code> to code non-dictionary words as zero by default.</p>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compute valence</span></span>
<span><span class="va">hippocorpus_valence</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/quanteda.sentiment/man/textstat_valence.html">textstat_valence</a></span><span class="op">(</span></span>
<span>  <span class="va">hippocorpus_dfm</span>, <span class="co"># data</span></span>
<span>  <span class="va">surprise_dict_hashtag</span>, <span class="co"># dictionary</span></span>
<span>  normalization <span class="op">=</span> <span class="st">"all"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># rejoin to original data</span></span>
<span><span class="va">hippocorpus_valence</span> <span class="op">&lt;-</span> <span class="va">hippocorpus_valence</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">rename</span><span class="op">(</span>surprise <span class="op">=</span> <span class="va">sentiment</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">right_join</span><span class="op">(</span></span>
<span>    <span class="va">hippocorpus_corp</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu"><a href="https://quanteda.io/reference/convert.html">convert</a></span><span class="op">(</span><span class="st">"data.frame"</span><span class="op">)</span> <span class="co"># convert to dataframe</span></span>
<span>    <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="modeling-norms" class="level3" data-number="14.5.1"><h3 data-number="14.5.1" class="anchored" data-anchor-id="modeling-norms">
<span class="header-section-number">14.5.1</span> Modeling Norms</h3>
<p>Norm scores, unlike raw word counts and polarities, can be reasonably modeled using standard linear regression. Furthermore, because the score is an average rather than a sum or count, there is no need to control for total word count. Let’s test one more time whether true autobiographical stories include more surprise-related language than imagined stories:</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">surprise_score_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">surprise</span> <span class="op">~</span> <span class="va">memType</span>, <span class="va">hippocorpus_valence</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">surprise_score_mod</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = surprise ~ memType, data = hippocorpus_valence)
#&gt; 
#&gt; Residuals:
#&gt;       Min        1Q    Median        3Q       Max 
#&gt; -0.085708 -0.015726 -0.000448  0.015093  0.104459 
#&gt; 
#&gt; Coefficients:
#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)     0.1402018  0.0004433 316.300  &lt; 2e-16 ***
#&gt; memTyperecalled 0.0029688  0.0006256   4.746 2.12e-06 ***
#&gt; memTyperetold   0.0021648  0.0007791   2.779  0.00548 ** 
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 0.02327 on 6851 degrees of freedom
#&gt; Multiple R-squared:  0.003406,   Adjusted R-squared:  0.003116 
#&gt; F-statistic: 11.71 on 2 and 6851 DF,  p-value: 8.388e-06</code></pre>
</div>
</div>
<p>We found a significant difference between recalled and imagined stories (p &lt; .001), such that recalled stories have more surprise-related language! This supports Sap et al.’s hypothesis that true autobiographical stories would include more surprising events than imagined stories. The new model also indicated a significant difference between retold and imagined stories, such that retold stories used <em>more</em> surprise-related language—the opposite direction relative to our original finding with the crowdsourced dictionary (p = 0.005).</p>
</section></section><section id="sec-dictionary-sources" class="level2" data-number="14.6"><h2 data-number="14.6" class="anchored" data-anchor-id="sec-dictionary-sources">
<span class="header-section-number">14.6</span> Sources of Dictionaries</h2>
<p>So far we have seen the NRC Word-Emotion Association Lexicon, which used a crowdsourcing approach to generate the dictionary, and the NRC Hashtag Emotion Lexicon, which used a corpus-based approach, relying on hashtags for labeling. Crowdsourcing and algorithmic corpus-based generation are far from the only ways to generate a dictionary. Here we review various types of dictionaries and where to find them.</p>
<section id="crowdsourced-dictionaries" class="level3" data-number="14.6.1"><h3 data-number="14.6.1" class="anchored" data-anchor-id="crowdsourced-dictionaries">
<span class="header-section-number">14.6.1</span> Crowdsourced Dictionaries</h3>
<p>Besides the surprise dictionary, the NRC Word-Emotion Association Lexicon includes dictionaries for anger, fear, anticipation, trust, sadness, joy, and disgust. The same group has also produced other crowdsourced emotion dictionaries:</p>
<ul>
<li>
<a href="https://saifmohammad.com/WebPages/nrc-vad.html">NRC VAD</a> <span class="citation" data-cites="mohammad_2018">(<a href="#ref-mohammad_2018" role="doc-biblioref">S. M. Mohammad, 2018a</a>)</span> contains 20,007 words with ratings between 0 and 1 for valence, arousal and dominance.</li>
<li>
<a href="http://saifmohammad.com/WebPages/AffectIntensity.htm">NRC Affect Intensity</a> <span class="citation" data-cites="mohammad_2018b">(<a href="#ref-mohammad_2018b" role="doc-biblioref">S. M. Mohammad, 2018b</a>)</span> contains 4192 words with ratings between 0 and 1 for anger, fear, sadness and joy.</li>
</ul>
<p>Psychologists have used crowdsourcing questionnaires to create dictionaries (especially norms) for decades. As such, crowdsourced dictionaries exist for many psychologically interesting constructs:</p>
<ul>
<li>
<span class="citation" data-cites="brysbaert_etal_2014">Brysbaert et al. (<a href="#ref-brysbaert_etal_2014" role="doc-biblioref">2014</a>)</span> used an internet questionnaire to obtain norms for concreteness (i.e.&nbsp;the extent to which a word refers to a perceptible entity). The result, including nearly 40,000 words and 2-grams, is available as an Excel file <a href="https://static-content.springer.com/esm/art%3A10.3758%2Fs13428-013-0403-5/MediaObjects/13428_2013_403_MOESM1_ESM.xlsx">here</a>.</li>
<li>
<span class="citation" data-cites="kuperman_etal_2012">Kuperman et al. (<a href="#ref-kuperman_etal_2012" role="doc-biblioref">2012</a>)</span> asked participants at what age they learned each word, resulting in age-of-acquisition norms for 30,000 English words.</li>
<li>
<span class="citation" data-cites="warriner_etal_2013">Warriner et al. (<a href="#ref-warriner_etal_2013" role="doc-biblioref">2013</a>)</span> crowdsourced norms for valence, arousal, and dominance, expanding on the ANEW dictionary included in <code>quanteda.sentiment</code>. The expanded norms are available as a zip file <a href="https://static-content.springer.com/esm/art%3A10.3758%2Fs13428-012-0314-x/MediaObjects/13428_2012_314_MOESM1_ESM.zip">here</a>.</li>
<li>
<span class="citation" data-cites="stadthagen_davis_2006">Stadthagen-Gonzalez &amp; Davis (<a href="#ref-stadthagen_davis_2006" role="doc-biblioref">2006</a>)</span> collected norms for age-of-acquisition, familiarity, and imageability (the ease with which a word evokes mental images) by surveying undergraduates.</li>
<li>
<span class="citation" data-cites="diveica_etal_2023">Diveica et al. (<a href="#ref-diveica_etal_2023" role="doc-biblioref">2023</a>)</span> asked online participants to rate the social relevance of words. The resulting “socialness” norms are available <a href="https://osf.io/yjz85/">here</a>.</li>
</ul></section><section id="expert-generated-dictionaries" class="level3" data-number="14.6.2"><h3 data-number="14.6.2" class="anchored" data-anchor-id="expert-generated-dictionaries">
<span class="header-section-number">14.6.2</span> Expert-Generated Dictionaries</h3>
<p>Words are used in many contexts, sometimes with many possible meanings. To take these into account, some groups rely on experts to generate their dictionaries. By far the most prominent collection of expert-generated dictionaries is <a href="https://www.liwc.app">LIWC</a> (pronounced “Luke”), which includes word lists for grammatical patterns, emotional content, cognitive processes, and more. With its rigorous approach, LIWC has dominated the field of dictionary-based analysis in psychology for decades. The most recent version of LIWC <span class="citation" data-cites="boyd_etal_2022">(<a href="#ref-boyd_etal_2022" role="doc-biblioref">Boyd et al., 2022</a>)</span> was generated by a team of experts who went through numerous stages of brainstorming, voting, and reliability analysis before arriving at the final word lists.</p>
</section><section id="corpus-based-dictionaries" class="level3" data-number="14.6.3"><h3 data-number="14.6.3" class="anchored" data-anchor-id="corpus-based-dictionaries">
<span class="header-section-number">14.6.3</span> Corpus-Based Dictionaries</h3>
<p>Human raters are much better at judging full texts than individual words. Corpus-based dictionaries take advantage of this by extracting their word lists from corpora of full texts that have been rated by humans. We have already seen the <a href="https://saifmohammad.com/WebPages/AccessResource.htm">NRC Hashtag Emotion Lexicon</a> <span class="citation" data-cites="mohammad_kiritchenko_2015">(<a href="#ref-mohammad_kiritchenko_2015" role="doc-biblioref">S. M. Mohammad &amp; Kiritchenko, 2015</a>)</span>, which used Twitter hashtags to gather a corpus of Tweets labeled with emotions by their original authors. A more classic example of corpus-based dictionary generation is <span class="citation" data-cites="rao_etal_2014">Rao et al. (<a href="#ref-rao_etal_2014" role="doc-biblioref">2014</a>)</span>, who used a corpus of 1,246 news headlines, each rated manually for anger, disgust, fear, joy, sad and surprise on a scale from 0 to 100 <span class="citation" data-cites="strapparava_mihalcea_2007">(<a href="#ref-strapparava_mihalcea_2007" role="doc-biblioref">Strapparava &amp; Mihalcea, 2007</a>)</span>. By correlating these ratings with frequencies of words (see <a href="dla.html" class="quarto-xref"><span>Chapter 15</span></a>), they extracted the words that were most representative of high ratings in each category. <span class="citation" data-cites="araque_etal_2018">Araque et al. (<a href="#ref-araque_etal_2018" role="doc-biblioref">2018</a>)</span> used a similar technique to create <a href="https://github.com/marcoguerini/DepecheMood">DepecheMood</a>, which includes ratings for each word on eight emotional dimensions: afraid, amused, angry, annoyed, don’t care, happy, inspired, and sad. This base dictionary was updated with additional resources by <span class="citation" data-cites="badaro_etal_2018">Badaro et al. (<a href="#ref-badaro_etal_2018" role="doc-biblioref">2018</a>)</span> to create EmoWordNet, which can be accessed <a href="https://web.archive.org/web/20210906101337/http://oma-project.com/ArSenL/EmoWordNet1.0.txt">through the Internet Archive</a>.</p>
<p>Many statistical techniques have been used to extract dictionaries from labeled corpora, some of which will be covered briefly in <a href="dla.html" class="quarto-xref"><span>Chapter 15</span></a> and <a href="decontextualized-embeddings.html" class="quarto-xref"><span>Chapter 18</span></a> of this book. For a recent review of methods, see <span class="citation" data-cites="bandhakavi_etal_2021">Bandhakavi et al. (<a href="#ref-bandhakavi_etal_2021" role="doc-biblioref">2021</a>)</span>.</p>
</section><section id="other-approaches-to-dictionary-generation" class="level3" data-number="14.6.4"><h3 data-number="14.6.4" class="anchored" data-anchor-id="other-approaches-to-dictionary-generation">
<span class="header-section-number">14.6.4</span> Other Approaches to Dictionary Generation</h3>
<ul>
<li><p><strong>Thesaurus Mining:</strong> <span class="citation" data-cites="strapparava_valitutti_2004">Strapparava &amp; Valitutti (<a href="#ref-strapparava_valitutti_2004" role="doc-biblioref">2004</a>)</span> started with a short list of strongly affect-related words (e.g.&nbsp;“anger”, “doubt”, “cry”), and used <a href="https://wordnet.princeton.edu">WordNet</a>, a database of conceptual relations between words, to find close synonyms of the original words on the list. The result was <a href="https://wndomains.fbk.eu/wnaffect.html">WordNet Affect</a>. <span class="citation" data-cites="strapparava_mihalcea_2007">Strapparava &amp; Mihalcea (<a href="#ref-strapparava_mihalcea_2007" role="doc-biblioref">2007</a>)</span> used WordNet Affect to generate short lists of words associated with anger, disgust, fear, joy, sadness, and surprise, downloadable from <a href="https://web.eecs.umich.edu/~mihalcea/affectivetext/">here</a>.</p></li>
<li><p><strong>Decontextualized Embeddings:</strong> In <a href="decontextualized-embeddings.html" class="quarto-xref"><span>Chapter 18</span></a>, we will cover a family of methods for measuring the similarities between words based on how frequently they appear together in text: decontextualized embeddings. These methods can be used on their own for measuring psychological constructs, but they can also be used as a tool for building dictionaries. For example, <span class="citation" data-cites="buechel_etal_2020">Buechel et al. (<a href="#ref-buechel_etal_2020" role="doc-biblioref">2020</a>)</span> started with a small seed lexicon and used word embeddings (<a href="decontextualized-embeddings.html#sec-word-embeddings" class="quarto-xref"><span>Section 18.3</span></a>) to find other words that are likely to appear in texts of the same topic. The result—including dictionaries for valence, arousal, dominance, joy anger, sadness, fear, and disgust—is <a href="https://zenodo.org/records/3756607">available for download online</a>.</p></li>
<li><p><strong>Combined Methods:</strong> <span class="citation" data-cites="vandervegt_etal_2021">Vegt et al. (<a href="#ref-vandervegt_etal_2021" role="doc-biblioref">2021</a>)</span> used a combination of expert input, thesaurus data from <a href="https://wordnet.princeton.edu">WordNet</a>, word embeddings (<a href="decontextualized-embeddings.html#sec-word-embeddings" class="quarto-xref"><span>Section 18.3</span></a>), and crowdsourcing from online participants to generate norms for numerous constructs associated with grievance-fueled violence (e.g.&nbsp;desperation, fixation, frustration, hate, weapons). The final product is available <a href="https://github.com/Isabellevdv/grievancedictionary/tree/main">here</a>.</p></li>
</ul>
<hr>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advantages of Dictionary-Based Word Counts
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>
<strong>Efficient Processing:</strong> Counting is a simple operation for computers. For very large datasets, this can make a big difference.</li>
<li>
<strong>Easy to Interpret:</strong> Dictionaries for sentiment analysis are usually not more than a few hundred words long. This means that they are easy to read through and understand intuitively. The intuitive appeal is also good for explaining your research to others—“we counted the number of anger-related words” is a method that any non-expert can understand.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Disadvantages of Dictionary-Based Word Counts
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>
<strong>No Context:</strong> Dictionary-based word counts treat texts as bags of words. This means they entirely ignore word order (aside from the order of any n-grams that might be included in the dictionary).</li>
<li>
<strong>May Reflect Various Constructs:</strong> Dictionaries are often generated by asking participants to identify associations with words. These associations do not necessarily reflect the construct in which the researcher is interested.</li>
<li>
<strong>Unnuanced:</strong> Words are either in a dictionary or they are not. Raw counts carry no nuance about the varying degrees to which different words may reflect the construct of interest. Norms can fix this problem, but are not available for many psychological dimensions.</li>
<li>
<strong>Unnaturalistic Generation Process:</strong> Dictionaries are generally crowdsourced by asking participants to report their associations with individual words. People presented words out of context often fail to consider how words are actually used in natural discourse.</li>
<li>
<strong>Limited Dictionaries Available:</strong> Dictionaries are expensive and labor intensive to produce. Researchers are generally reliant on dictionaries already produced by other teams, which may not reflect the construct of interest precisely.</li>
</ul>
</div>
</div>
<hr>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-araque_etal_2018" class="csl-entry" role="listitem">
Araque, O., Gatti, L., Staiano, J., &amp; Guerini, M. (2018). DepecheMood++: A bilingual emotion lexicon built through simple yet powerful techniques. <em>CoRR</em>, <em>abs/1810.03660</em>. <a href="http://arxiv.org/abs/1810.03660">http://arxiv.org/abs/1810.03660</a>
</div>
<div id="ref-baayen_2001" class="csl-entry" role="listitem">
Baayen, R. H. (2001). <em>Word frequency distributions</em>. Springer Netherlands. <a href="https://link.springer.com/book/10.1007/978-94-010-0844-0">https://link.springer.com/book/10.1007/978-94-010-0844-0</a>
</div>
<div id="ref-badaro_etal_2018" class="csl-entry" role="listitem">
Badaro, G., Jundi, H., Hajj, H., &amp; El-Hajj, W. (2018). <span>E</span>mo<span>W</span>ord<span>N</span>et: Automatic expansion of emotion lexicon using <span>E</span>nglish <span>W</span>ord<span>N</span>et. In M. Nissim, J. Berant, &amp; A. Lenci (Eds.), <em>Proceedings of the seventh joint conference on lexical and computational semantics</em> (pp. 86–93). Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/S18-2009">https://doi.org/10.18653/v1/S18-2009</a>
</div>
<div id="ref-bandhakavi_etal_2021" class="csl-entry" role="listitem">
Bandhakavi, A., Wiratunga, N., Massie, S., &amp; P., D. (2021). Emotion‐aware polarity lexicons for twitter sentiment analysis. <em>Expert Systems</em>, <em>38</em>(7).
</div>
<div id="ref-boyd_etal_2022" class="csl-entry" role="listitem">
Boyd, R., Ashokkumar, A., Seraj, S., &amp; Pennebaker, J. (2022). <em>The development and psychometric properties of LIWC-22</em>. <a href="https://doi.org/10.13140/RG.2.2.23890.43205">https://doi.org/10.13140/RG.2.2.23890.43205</a>
</div>
<div id="ref-brysbaert_etal_2014" class="csl-entry" role="listitem">
Brysbaert, M., Warriner, A. B., &amp; Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known english word lemmas. <em>Behavior Research Methods</em>, <em>46</em>, 904–911.
</div>
<div id="ref-buechel_etal_2020" class="csl-entry" role="listitem">
Buechel, S., Rücker, S., &amp; Hahn, U. (2020). Learning and evaluating emotion lexicons for 91 languages. In D. Jurafsky, J. Chai, N. Schluter, &amp; J. Tetreault (Eds.), <em>Proceedings of the 58th annual meeting of the association for computational linguistics</em> (pp. 1202–1217). Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.acl-main.112">https://doi.org/10.18653/v1/2020.acl-main.112</a>
</div>
<div id="ref-diveica_etal_2023" class="csl-entry" role="listitem">
Diveica, V., Pexman, P. M., &amp; Binney, R. J. (2023). Quantifying social semantics: An inclusive definition of socialness and ratings for 8388 english words. <em>Behavior Research Methods</em>, <em>55</em>(2), 461–473.
</div>
<div id="ref-kuperman_etal_2012" class="csl-entry" role="listitem">
Kuperman, V., Stadthagen-Gonzalez, H., &amp; Brysbaert, M. (2012). Age-of-acquisition ratings for 30,000 english words. <em>Behavior Research Methods</em>, <em>44</em>, 978–990.
</div>
<div id="ref-mohammad_2018" class="csl-entry" role="listitem">
Mohammad, S. M. (2018a). Obtaining reliable human ratings of valence, arousal, and dominance for 20,000 english words. <em>Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL)</em>.
</div>
<div id="ref-mohammad_2018b" class="csl-entry" role="listitem">
Mohammad, S. M. (2018b). Word affect intensities. <em>Proceedings of the 11th Edition of the Language Resources and Evaluation Conference (LREC-2018)</em>.
</div>
<div id="ref-mohammad_kiritchenko_2015" class="csl-entry" role="listitem">
Mohammad, S. M., &amp; Kiritchenko, S. (2015). Using hashtags to capture fine emotion categories from tweets. <em>Computational Intelligence</em>, <em>31</em>, 301–326. <a href="https://api.semanticscholar.org/CorpusID:2498838">https://api.semanticscholar.org/CorpusID:2498838</a>
</div>
<div id="ref-mohammad_turney_2013" class="csl-entry" role="listitem">
Mohammad, S. M., &amp; Turney, P. D. (2013). Crowdsourcing a word-emotion association lexicon. <em>Computational Intelligence</em>, <em>29</em>(3), 436–465.
</div>
<div id="ref-mohammad_turney_2010" class="csl-entry" role="listitem">
Mohammad, S., &amp; Turney, P. (2010). Emotions evoked by common words and phrases: Using <span>M</span>echanical <span>T</span>urk to create an emotion lexicon. <em>Proceedings of the <span>NAACL</span> <span>HLT</span> 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</em>, 26–34. <a href="https://aclanthology.org/W10-0204">https://aclanthology.org/W10-0204</a>
</div>
<div id="ref-plutchik_1962" class="csl-entry" role="listitem">
Plutchik, R. (1962). <em>The emotions</em>. Random House.
</div>
<div id="ref-rao_etal_2014" class="csl-entry" role="listitem">
Rao, Y., Lei, J., Wenyin, L., Li, Q., &amp; Chen, M. (2014). Building emotional dictionary for sentiment analysis of online news. <em>World Wide Web (Bussum)</em>, <em>17</em>(4), 723–742.
</div>
<div id="ref-sap_etal_2022" class="csl-entry" role="listitem">
Sap, M., Jafarpour, A., Choi, Y., Smith, N. A., Pennebaker, J. W., &amp; Horvitz, E. (2022). Quantifying the narrative flow of imagined versus autobiographical stories. <em>Proceedings of the National Academy of Sciences</em>, <em>119</em>(45), e2211715119. <a href="https://doi.org/10.1073/pnas.2211715119">https://doi.org/10.1073/pnas.2211715119</a>
</div>
<div id="ref-simchon_etal_2023" class="csl-entry" role="listitem">
Simchon, A., Hadar, B., &amp; Gilead, M. (2023). A computational text analysis investigation of the relation between personal and linguistic agency. <em>Communications Psychology</em>, 1–9. <a href="https://doi.org/10.1038/s44271-023-00020-1">https://doi.org/10.1038/s44271-023-00020-1</a>
</div>
<div id="ref-stadthagen_davis_2006" class="csl-entry" role="listitem">
Stadthagen-Gonzalez, H., &amp; Davis, C. J. (2006). The bristol norms for age of acquisition, imageability, and familiarity. <em>Behavior Research Methods</em>, <em>38</em>(4), 598–605.
</div>
<div id="ref-strapparava_mihalcea_2007" class="csl-entry" role="listitem">
Strapparava, C., &amp; Mihalcea, R. (2007). <span>S</span>em<span>E</span>val-2007 task 14: Affective text. In E. Agirre, L. Màrquez, &amp; R. Wicentowski (Eds.), <em>Proceedings of the fourth international workshop on semantic evaluations (<span>S</span>em<span>E</span>val-2007)</em> (pp. 70–74). Association for Computational Linguistics. <a href="https://aclanthology.org/S07-1013">https://aclanthology.org/S07-1013</a>
</div>
<div id="ref-strapparava_valitutti_2004" class="csl-entry" role="listitem">
Strapparava, C., &amp; Valitutti, A. (2004). Wordnet affect: An affective extension of wordnet. <em>Lrec</em>, <em>4</em>, 40.
</div>
<div id="ref-vandervegt_etal_2021" class="csl-entry" role="listitem">
Vegt, I. van der, Mozes, M., Kleinberg, B., &amp; Gill, P. (2021). The grievance dictionary: Understanding threatening language use. <em>Behavior Research Methods</em>, 1–15.
</div>
<div id="ref-warriner_etal_2013" class="csl-entry" role="listitem">
Warriner, A. B., Kuperman, V., &amp; Brysbaert, M. (2013). Norms of valence, arousal, and dominance for 13,915 english lemmas. <em>Behavior Research Methods</em>, <em>45</em>, 1191–1207.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>We use total word count here for the sake of the example, but total word count may not always be the appropriate measure of text length. For example, you may want to measure the amount of surprise <em>relative to other emotional content</em>. In this case, it would be more appropriate to control for the total number of emotion-related words, as opposed to the total word count. Similarly, if you were measuring the number of first person singular pronouns, you may want to control for the total number of pronouns rather than the total word count.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>We use a simple count of words as the dependent variable here, but keep in mind that it may be more appropriate to apply a transformation such as Simple Good-Turing frequency estimation (<a href="word-counting-improvements.html#sec-smoothing" class="quarto-xref"><span>Section 16.6</span></a>).<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ds4psych\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./tokenization.html" class="pagination-link" aria-label="Tokenization">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Tokenization</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./dla.html" class="pagination-link" aria-label="Open Vocabulary Word Counting">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Open Vocabulary Word Counting</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Data Science for Psychology was written by <a href="https://rimonim.github.io">Louis Teitelbaum</a> and <a href="https://almogsi.com">Almog Simchon</a>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/rimonim/ds4psych/blob/main/word-counting.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/rimonim/ds4psych/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a> and is powered by <a href="https://www.netlify.com/">Netlify</a></p>
</div>
  </div>
</footer>


</body></html>